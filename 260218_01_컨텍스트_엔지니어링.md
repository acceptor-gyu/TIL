# 컨텍스트 엔지니어링

## 개요
AI Agent의 성능을 극대화하기 위해 적절한 컨텍스트를 설계하고 제공하는 전략과 기법. 2026년 현재, 프롬프트 엔지니어링을 넘어 정보 아키텍처 전반을 다루는 더 포괄적인 접근법으로 부상하고 있다.

**Anthropic의 정의:** LLM 추론 중 최적의 토큰 세트를 큐레이션하고 유지하는 전략 - 시스템 지시사항, 도구, MCP, 외부 데이터, 메시지 히스토리를 모두 포함한다.

**핵심 원칙:** "원하는 결과의 가능성을 최대화하는 최소한의 고신호 토큰 세트를 찾는 것"

## 상세 내용

### 1. 컨텍스트 엔지니어링이란

#### 프롬프트 엔지니어링과의 차이점
- **프롬프트 엔지니어링**: "어떻게 말할 것인가(How to say)" - 한 번의 상호작용에서 모델에게 지시하는 방법에 집중
- **컨텍스트 엔지니어링**: "무엇을 알게 할 것인가(What to know)" - 모델이 응답을 생성할 때 접근할 수 있는 전체 정보 환경 설계

2026년 현재, 프롬프트 엔지니어링은 컨텍스트 엔지니어링의 **하위 집합(subset)**으로 재정의되고 있다. 프롬프트는 컨텍스트가 구축한 컨테이너 안에서 작동하며, 단순히 "어떻게 질문할 것인가"보다는 "모델에게 어떤 정보와 환경을 제공해야 작업을 효과적으로 수행할 수 있는가"가 더 중요해졌다.

#### 왜 프롬프트 엔지니어링만으로는 부족한가?
- **동적 작업 상태를 처리할 수 없음**: Multi-step Agent는 각 단계에서 구조화된 맞춤형 컨텍스트가 필요하며, 프롬프트만으로는 이를 다룰 수 없음
- **스케일 문제**: 초기 실험 단계에서는 프롬프트가 충분했지만, 프로덕션 규모로 확장하면 정확성, 메모리, 거버넌스 요구사항을 충족할 수 없음
- **Agent 실패의 본질**: 대부분의 Agent 실패는 컨텍스트 실패(누락된 데이터, 잘못된 포맷, 도구 오용)에서 비롯되며, 완벽한 프롬프트로도 이를 보완할 수 없음

#### 컨텍스트 윈도우의 구조와 활용
- **컨텍스트 윈도우는 작업 메모리일 뿐**: Claude Opus 4.6(200K 토큰), GPT-5.2(400K 토큰), Gemini 3 Pro(2M 토큰) 등 대형 컨텍스트 윈도우가 등장했지만, 이것이 Agent 메모리 문제를 해결한 것은 아님
- **외부 메모리 시스템이 필수**: 전체 대화 기록을 매 API 호출에 주입하면 비용과 지연시간이 감당 불가능해짐. 프로덕션 Agent는 외부 메모리 시스템(에피소딕 DB, 벡터 스토어, 그래프 구조)을 필요로 함

#### Context Rot (컨텍스트 부패) 문제

**왜 컨텍스트가 길어지면 AI Agent의 성능이 떨어지는가?**

**1. 주의 희석(Attention Dilution) - 핵심 문제**

Transformer의 "Soft Attention" 메커니즘의 본질적 한계다. 컨텍스트 길이가 증가하면 모델의 주의가 **희석**되어 입력 내 중요 정보의 영향력이 실질적으로 감소한다.

- 컨텍스트가 커질수록 주의 메커니즘의 확률 질량이 더 얇게 분산됨
- 1,000만 토큰 윈도우에서 관련 문장 하나는 수백만 개의 방해 토큰에 비해 통계적으로 무의미해짐
- 이론적 분석: **softmax attention이 희소한 정보 토큰의 기여도를 소멸시킴** (컨텍스트 길이 증가 시)

**2. Self-Attention의 이차 복잡도(Quadratic Complexity)**

표준 Attention 메커니즘은 모든 토큰 쌍에 대해 주의 가중치를 계산하여 **O(n²) 복잡도**를 가진다.

- n개의 토큰에 대해 **n² 쌍별 관계** 생성
- 계산 및 메모리 요구사항이 시퀀스 길이에 따라 **이차적으로 증가**
- **구체적 영향**:
  - 4,096 토큰 모델은 512 토큰 모델 대비 **64배 더 많은 계산** 필요
  - 4K 컨텍스트에서는 attention이 ~8% 오버헤드
  - 128K 컨텍스트에서는 attention이 **~260% 오버헤드** (지배적 요인)
  - 1주일 걸리던 학습이 128K 컨텍스트에서 **3.5주** 소요
- LLM이 새 토큰 생성 전 최신 토큰을 모든 이전 토큰과 비교 → 토큰당 컴퓨팅 파워 증가
  - 101개 토큰: 100회 attention 연산
  - 1,001개 토큰: 1,000회 attention 연산
  - **10배 토큰 → 약 100배 컴퓨팅 파워**

**3. "Lost in the Middle" 현상 - 위치 편향**

Stanford/UW 연구(Liu et al., 2024, TACL)의 핵심 발견:

- **U자형 성능 곡선**: 관련 정보가 입력 컨텍스트의 시작(primacy bias) 또는 끝(recency bias)에 있을 때 성능이 가장 높음
- 정보가 **중간**에 있을 때 성능이 크게 저하
- **30% 이상 성능 저하** 가능 (위치 변경 시)
- **GPT-3.5-Turbo 예시**: 관련 정보가 중간에 있을 때 성능이 문서 없이 예측하는 것보다 낮음 (56.1%)
- **명시적 장문 컨텍스트 모델도 면역 없음**: 컨텍스트 길이 증가 시 성능 감소
- **13B 모델**: 최상/최악 성능 간 20포인트 차이

**4. "Know But Don't Tell" 현상 - 내부 인코딩 vs 출력 단절**

- LLM이 은닉 표현에서 대상 정보의 위치를 인코딩하지만, 정확한 응답 생성에 이를 활용하지 못함
- 정보 검색과 활용 간의 단절
- 내부적으로는 "알지만" 외부로는 "말하지 않는" 현상

**5. Context Rot - 비균일적, 작업 특정적 성능 저하**

- 최소 조건에서도 입력 길이 증가 시 모델 성능 저하
- **비균일적** 방식으로 저하 (예측 불가능)
- Needle-question 유사도가 낮을수록 입력 길이 증가에 따른 성능 저하 더 심각
- 의미적 모호성이 장문 입력 처리의 어려움을 가중

**6. 2026년 연구: 프라이버시 & 개인화 스케일링 갭**

Oxford, UCL, Alan Turing Institute 연구:

- **PAPerBench** 벤치마크: 1,000~256,000 토큰 컨텍스트에서 377,000개 평가 질문
- 컨텍스트 윈도우 증가 시 개인화 능력과 프라이버시 보호 **모두 감소**
- 주요 실패 메커니즘: **환각(hallucination), 구조적 위반, 취약한 구성적 추론**
- 주의 희석은 **작업 불가지론적** → 성능 저하가 프라이버시/개인화를 넘어 광범위한 장문 시나리오로 확장

**7. 성능 저하의 근본 원인 요약**

컨텍스트가 길어질수록:
- 검색 정밀도 감소
- 장거리 추론 능력 저하
- 성능이 점진적으로(gradient) 감소 (하드 컷오프가 아님)
- 단순히 컨텍스트를 늘리는 것만으로는 문제 해결 불가능

**이것이 아키텍스트적 한계이지 단순한 엔지니어링 문제가 아닌 이유다.**

**8. 제안된 해결책들**

이차 복잡도 문제를 극복하기 위한 연구 방향:

**효율적 Attention 메커니즘:**
- **FlashAttention**: N×N attention 행렬을 구체화하지 않음. Tiling(블록 단위로 GPU SRAM 로드) + Recomputation(역전파 시 재구성) 사용
- **Sparse Attention**: 고정 패턴, 블록 라우팅, 클러스터링으로 선택된 토큰 하위집합으로만 계산 제한
- **LSH Attention** (Reformer): 유사 토큰 그룹화, 그룹 내에서만 attention 계산 → **이차에서 로그-선형 복잡도**로 감소
- **Linear Attention / RWKV**: O(n) 시간 복잡도, O(1) 추가 메모리, "100% attention-free" 선형 스케일링
- **Dilated Attention** (LONGNET): 토큰의 attention을 시퀀스에 걸쳐 "희석" 분산 → **이차에서 선형 복잡도**로 감소

**대안적 접근:**
- **Chunk Attention**: 입력을 고정 크기 청크로 분할, 청크 내부 + 청크 간 표현으로 attention 계산
- **Recursive Language Models (RLMs)** (MIT 2025): AI가 Python 코드를 작성하여 방대한 컨텍스트에 접근/분해, 관리 가능한 청크에서 작은 버전의 자신을 호출 → 복잡한 작업에서 **12-58% 성능 향상**, 종종 저비용

**한계:**
- FlashAttention, Ring Attention 같은 엔지니어링 솔루션에도 불구하고 **attention은 근본적으로 제한됨**
- 윈도우 스케일링은 attention 확산을 수정하지 못하며, 단지 목표를 이동시킬 뿐
- **희소성과 복잡도 간의 본질적 트레이드오프**: 희소 attention은 효율성/확장성 개선하지만 표현력/정확도 희생 가능

**RAG 시스템 실전 대응:**
- 2단계 검색: 광범위한 재현 + 크로스 인코더 재랭킹
- 하이브리드 검색: Semantic + BM25
- 전략적 순서: 상위 증거를 시작과 끝에 배치
- 컨텍스트 청킹 + 가장 관련성 높은 3-5개 문서만 프롬프트에 유지

이것은 현재 LLM 연구의 **가장 활발하고 중요한 미해결 과제** 중 하나다.

### 2. 컨텍스트 구성 요소

AI Agent는 **3가지 핵심 능력**의 조화로 작동한다:
1. **Planning (계획)** - LLM 기반 추론과 작업 분해
2. **Tool Utilization (도구 활용)** - 외부 시스템과의 상호작용
3. **Memory Systems (메모리)** - 정보 저장 및 검색

이 세 요소의 시너지가 효과적인 AI Agent의 기반을 형성한다. 계획은 도구 사용을 지시하고, 도구는 메모리를 채우며, 메모리는 미래의 계획에 정보를 제공한다.

**Agent의 간소화된 정의:** "도구를 자율적으로 사용하는 LLM의 루프" - 모델이 개선될수록 덜 지시적인 엔지니어링으로 더 많은 자율성을 갖게 된다.

#### System Prompt 설계

**"적절한 고도(Right Altitude)" 원칙**

두 가지 실패 모드를 피해야 한다:

| Too Brittle (너무 취약함) | Too Vague (너무 모호함) |
|---|---|
| 하드코딩된 if-else 논리 | 구체적 신호 없는 고수준 가이던스 |
| 취약성 생성 | 공유 컨텍스트를 잘못 가정 |

**목표:** 행동을 안내할 만큼 구체적이면서도 강력한 휴리스틱을 제공할 만큼 유연해야 함.

**구조 권장사항:**
- 명확한 섹션 구분: `<background_information>`, `<instructions>`, `## Tool guidance`, `## Output description`
- XML 태그 또는 Markdown 헤더로 구분
- 최소한으로 시작 → 테스트 → 관찰된 실패 모드를 기반으로 지시사항 추가
- **"최소한(Minimal)"이 반드시 "짧음(Short)"을 의미하지는 않음**

**구성:**
- Agent의 역할, 제약사항, 목표를 정의하는 고정된 지시사항
- 프롬프트 엔지니어링의 핵심 요소이자, 컨텍스트 엔지니어링의 일부분
- 일관성 있는 톤, 스타일, 응답 형식을 보장

#### Few-shot Examples 배치 전략
- 작업 수행 방식의 예시를 제공하여 모델의 학습 유도
- 예시의 개수, 다양성, 배치 순서가 성능에 영향
- 컨텍스트 윈도우 제약 내에서 효율적으로 배치

**Anthropic의 권장사항:**
- **다양하고 표준적인 예시** 사용 (모든 엣지 케이스를 나열하는 대신)
- 예시는 LLM에게 "천 마디 말보다 가치 있는 그림"
- 모든 가능한 규칙을 예시로 프롬프트에 채우지 말 것

#### 외부 지식(RAG) 주입 방식
**RAG (Retrieval-Augmented Generation)**는 LLM을 외부 데이터 소스에 연결하여 실시간, 전문화된 정보로 강화하는 하이브리드 기술이다.

**핵심 구성 요소:**
1. **검색 정확도(Retrieval Accuracy)**: 최근접 이웃 매칭의 품질
2. **컨텍스트 품질(Context Quality)**: LLM에 제공되는 응답 생성용 컨텍스트

**RAG 최적화 모범 사례:**
- **데이터 준비 & 청킹**: 문서를 의미론적으로 일관된 단위(300-500 토큰)로 분할, 메타데이터 태그(작성자, 날짜, 카테고리) 추가로 필터링 및 관련성 랭킹 지원
- **검색 최적화**: 쿼리 증강(Query Augmentation)으로 모호한 쿼리 보완, 재랭킹(Reranking)으로 가장 관련성 높은 항목 우선 배치
- **컨텍스트 윈도우 관리**: 프롬프트 과다 주입 방지(상위 N개 청크만 주입), 문서 전체 vs 매칭 청크 전달 전략 테스트
- **평가**: RAGAS 툴킷으로 Context Precision, Context Recall, Faithfulness, Answer Relevancy 측정

#### Tool/Function 정의와 컨텍스트 내 역할
- Tool/Function은 Agent가 외부 시스템과 상호작용하는 수단
- Tool 정의(이름, 파라미터, 설명)는 컨텍스트의 일부로 모델에 제공
- 적절한 Tool 선택과 사용법은 컨텍스트가 명확할 때 향상됨

**도구 설계 원칙 (Anthropic):**
- **자체 완결적(self-contained)이고 오류에 강해야 함** - 목적이 명확해야 함
- **입력 파라미터**: 설명적이고 모호하지 않아야 함
- **비대한 도구 세트 피하기** - 인간이 어떤 도구를 사용해야 할지 말할 수 없다면 Agent도 할 수 없음
- **최소 실행 가능 도구 세트** → 긴 상호작용에서 컨텍스트 유지가 더 쉬움

**도구 유형:**
- 코드 인터프리터/실행 환경
- 웹 검색 및 스크래핑 유틸리티
- 수학 계산기
- 이미지 생성 시스템

도구는 계획된 전략을 구체적인 결과로 연결하는 다리 역할을 한다.

### 3. 컨텍스트 최적화 기법

#### 토큰 예산 관리와 우선순위 결정
LLM에 전송되는 모든 토큰에는 API 비용과 처리 시간이 발생한다. RAG 시스템, Agent, 챗봇 애플리케이션에서 컨텍스트는 수천 토큰으로 급증할 수 있으며, 컨텍스트 압축은 모델에 도달하기 전에 중복되거나 관련 없는 저가치 콘텐츠를 제거하여 이 문제를 해결한다.

**핵심 전략:**
- 저장 대상 결정: Salience(중요도) + Novelty(새로움) + Pinned Constraints(고정 제약)
- 검색 우선순위: 하이브리드 Semantic + Episodic 검색에 사용 빈도 감쇠 적용
- 단기 메시지를 지속 가능한 메모리로 통합

#### 컨텍스트 압축(Summarization, Truncation)

**주요 기법:**

1. **Semantic Summarization (의미론적 요약)**: 긴 콘텐츠나 반복적인 내용을 핵심 의미는 유지하면서 간결하게 압축

2. **Extractive Summarization (추출적 요약)**: 토큰 예산 내에서 가장 중요한 문장을 선택 (새 문장 생성 없이 원본 문장 유지)

3. **Relevance Filtering (관련성 필터링)**: 작업과 실제로 관련된 컨텍스트만 포함 (50-80% 토큰 절감 가능)

4. **Semantic Deduplication (의미론적 중복 제거)**: 의미상 중복되는 내용 제거

5. **Structured Prompting / Compact Formatting**: JSON, bullet points 등 컴팩트한 형식으로 변환하여 토큰 수 감소

6. **Sparse Attention Mechanisms**: Longformer, BigBird 등 모델에서 모든 토큰이 서로 상호작용하지 않고 하위 집합만 고려

7. **Hierarchical / Compressed Token Representations**: 토큰-문장-문단 계층 구조로 압축된 표현 사용

8. **Embedding-Based Context Compression**: 긴 컨텍스트를 밀집 임베딩 메모리 슬롯으로 압축

**압축 비율:**
- Relevance Filtering + Deduplication + Extractive Summarization: **50-80% 절감**
- Document Compression (필러/중복 제거): **40-60% 절감**
- LLMLingua-style RL methods: **최대 20배 단축**

**주의사항:**
- 요약은 새 문장 생성으로 환각(hallucination) 위험 존재
- 압축은 원본 표현 유지하지만 중복 제거 - 정밀도 측면에서 더 안전
- 비용 절감과 품질 보존의 균형이 핵심

#### 동적 컨텍스트 선택(Retrieval-Augmented Generation)
- 작업, 사용자, 과거 활동에 따라 정보를 **동적으로** 조합
- 동일한 질문이라도 주변 데이터 변화에 따라 다른 답변 생성 가능
- 정적 프롬프트와 달리 실시간으로 컨텍스트 구성

**컨텍스트 검색 전략 (Anthropic):**

**1. Pre-inference (RAG - 사전 추론)**
- 추론 전 임베딩 기반 검색
- 빠르지만 오래될 수 있음

**2. Just-in-Time (Agentic - 적시)**
- Agent가 **경량 식별자**(파일 경로, 쿼리, 링크)를 유지
- 런타임에 도구를 통해 데이터를 동적으로 로드
- 인간의 인지를 모방 - 암기보다는 인덱싱/북마킹 사용
- **점진적 공개(Progressive Disclosure)** 가능: Agent가 레이어별로 컨텍스트 발견

**3. Hybrid (권장)**
- 속도를 위해 일부 데이터를 미리 로드 (예: CLAUDE.md 파일)
- 적시 검색을 위해 `glob`/`grep` 같은 프리미티브 사용
- 덜 동적인 콘텐츠(법률, 금융)에 최적

**트레이드오프:** 런타임 탐색은 느리지만 오래된 인덱스를 피할 수 있음.

#### 불필요한 정보 제거와 노이즈 최소화
- 작업과 무관한 정보는 모델의 주의를 분산시키고 성능 저하
- 명확한 관련성 기준 설정 및 필터링 파이프라인 구축
- 검색 결과의 신호 대 잡음 비율 최적화

### 4. 장기 작업(Long-Horizon Tasks)을 위한 컨텍스트 기법

컨텍스트 한계에 도달하는 긴 대화나 복잡한 작업을 처리하기 위한 3가지 핵심 기법:

#### 1. Compaction (압축/요약)

컨텍스트 한계에 가까워진 대화를 요약하여 압축된 요약본으로 재시작.

**구현 팁:**
- 메시지 히스토리를 모델에 전달하여 자체 요약 수행
- **보존할 것**: 아키텍처 결정, 미해결 버그, 구현 세부사항
- **버릴 것**: 중복된 도구 출력
- **Recall(재현율)**을 최대화한 후 **Precision(정밀도)**을 위해 반복
- **도구 결과 지우기** = 가장 가벼운 압축 (히스토리에서 원시 도구 결과만 제거)

*Claude Code 예시:* 압축된 컨텍스트 + 가장 최근에 접근한 5개 파일

**언제 사용:** 앞뒤 대화가 필요한 작업

#### 2. Structured Note-Taking (구조화된 노트 작성) - Agentic Memory

- Agent가 컨텍스트 윈도우 **외부**에 영구적 노트 작성
- 나중에 노트를 다시 로드
- 예: `NOTES.md` 또는 할 일 목록 유지
- Claude가 포켓몬 플레이 실험: 명시적 메모리 프롬프트 없이 수천 단계에 걸쳐 게임 상태 추적

**신규:** Claude Developer Platform의 Memory 도구 (공개 베타) - 세션 간 지속성을 위한 파일 기반 저장 시스템

**언제 사용:** 명확한 이정표가 있는 반복적 개발

#### 3. Sub-Agent Architectures (서브 에이전트 아키텍처)

- 전문화된 서브 Agent가 **깨끗한 컨텍스트 윈도우**로 집중된 작업 처리
- 각 서브 Agent는 수만 토큰을 사용할 수 있지만 약 1,000-2,000 토큰 요약만 반환
- 리드 Agent가 결과를 통합; 세부사항은 서브 Agent에 격리됨
- 복잡한 연구 작업에서 단일 Agent 시스템 대비 **실질적인 개선** 입증

**언제 사용:** 병렬 탐색이 필요한 복잡한 연구

| 기법 | 최적 사용 사례 |
|---|---|
| Compaction | 앞뒤 대화가 필요한 작업 |
| Note-taking | 명확한 이정표가 있는 반복적 개발 |
| Multi-agent | 병렬 탐색이 필요한 복잡한 연구 |

### 5. Agent 아키텍처에서의 컨텍스트 관리

#### Multi-turn 대화에서의 컨텍스트 유지 전략
- **Stateless에서 Stateful로**: 초기 생성형 AI는 상태 비저장(stateless)이었으나, 자율형 Agent는 여러 상호작용에 걸쳐 지속되고 순차적 의사결정을 수행
- **대화 체인 관리**: 이전 교환 내용을 기억하여 고립된 입력이 아닌 일관된 응답 제공
- **컨텍스트 윈도우 활용**: 최근 메시지 + 요약된 그래프 상태를 컨텍스트 윈도우 내에 유지하여 빠른 접근

#### Agent 간 컨텍스트 전달(Sub-agent, Handoff)
- **Sub-agent 위임**: 복잡한 작업을 전문화된 하위 Agent에 위임할 때 필요한 컨텍스트만 선별적으로 전달
- **Handoff 프로토콜**: Agent 간 작업 전환 시 컨텍스트 손실 방지를 위한 명시적 인터페이스 정의
- **컨텍스트 격리**: 각 Agent가 필요한 정보만 접근하도록 네임스페이스 분리 (`user_id` 등)

#### Memory 계층 구조(Short-term, Long-term, Working Memory)

**AI Agent 메모리는 인간의 기억 체계와 유사하게 분류된다.** 메모리 인프라 없이는 LLM이 각 요청을 독립적으로 처리하지만, 메모리 시스템은 상호작용 간 정보를 저장하고 검색하여 컨텍스트를 유지하고 경험에서 학습하며 다단계 작업을 실행하는 Agent를 가능하게 한다.

**1. Short-Term / Working Memory (단기/작업 메모리)**
- **역할**: 현재 상호작용 내에서 즉각적인 컨텍스트 유지 - Agent의 작업 메모리
- **예시**: "파리행 항공편을 찾고, 루브르 박물관 근처 호텔 추천해줘" 같은 다단계 쿼리에서 각 단계의 결과를 추적하여 다음 작업에 활용
- **구현**: Rolling Buffer 또는 Context Window 사용, 제한된 최근 데이터를 보유하다가 덮어씀

**2. Long-Term Memory (장기 메모리)**
- **역할**: 세션 경계를 넘어 정보 지속, 개인화된 사용자 경험 구축, 시간에 걸친 사용자 프로필 및 선호도 유지
- **아키텍처**: 의미 있는 정보를 식별하는 추출 파이프라인 → 데이터를 정제하는 통합 프로세스 → 의미 유사성 검색을 위한 벡터 DB를 통한 지능형 검색
- **변환**: 단기 대화를 세션 간 지속되는 실행 가능한 지식으로 변환

**3. Episodic, Semantic & Procedural Memory (에피소딕, 의미론적, 절차적 메모리)**

경험에서 학습하고, 지식을 축적하며, 복잡한 작업을 수행하는 Agent를 구축하려면 세 가지 장기 메모리 유형 구현이 필요:

- **Episodic Memory (에피소딕 메모리)**: 시간적 세부사항이 포함된 특정 과거 경험 캡처. 벡터 DB로 의미론적 검색, 이벤트 로그로 ground truth 저장
- **Semantic Memory (의미론적 메모리)**: 특정 경험과 무관한 사실적 지식 저장 (고객 프로필, 제품 사양, 도메인 전문지식)
- **Procedural Memory (절차적 메모리)**: 학습된 전략 저장 (예: 코딩 어시스턴트의 디버깅 전략)

**2026년 프로덕션 표준: Dual-Layer Memory Architecture**

- **Hot Path**: 즉각적인 컨텍스트 처리 - 최근 메시지 + 요약된 그래프 상태, 컨텍스트 윈도우 내에서 빠른 접근
- **Cold Path**: 외부 스토어(Zep, Mem0, Pinecone)에서 필요시 관련 과거 정보 검색
- **Memory Node**: 백그라운드 그래프 노드로 실행되어 각 대화 턴 후 장기 저장소에 저장할 내용 합성
- **안티패턴 방지**: 모든 것을 컨텍스트에 덤프하는 일반적인 실수 방지

**2026년 핵심 도구 & 프레임워크:**
- **Zep**: Temporal Knowledge Graphs - 복잡한 추론 Agent의 정확성에 중요
- **Mem0**: 개인화를 위한 사용자 선호도 메모리 (전체 컨텍스트 방식 대비 **91% 낮은 응답 시간**)
- **PostgresSaver**: LangGraph 체크포인트의 프로덕션 표준 (일시정지/재개 신뢰성), Redis 대체

**모범 사례:**
- **4가지 핵심 결정**: 무엇을 저장할지, 어떻게 저장할지, 어떻게 검색할지, 언제 잊을지
- **보안**: `user_id`를 엄격한 네임스페이스 파티션 키로 사용하여 테넌트 격리, Zep의 내장 PII 삭제(GDPR 준수), 임베딩에 원시 PII 저장 금지
- **성능**: 검색 작업의 p99 지연시간을 **100ms 이하**로 목표 설정

### 6. AI Agent의 7가지 핵심 컴포넌트

현대 LLM 기반 AI Agent 아키텍처의 핵심 구성 요소:

#### 1. Planning & Reasoning (계획 및 추론)
- Agent의 "두뇌" - 목표 달성을 위한 행동 순서 결정
- Chain-of-thought 추론을 통한 작업 분해
- 과거 행동에 대한 자기 성찰
- 미래 결정을 위한 적응적 학습
- 중요한 진행 상황 분석

강력한 계획 없이는 복잡한 작업을 효과적으로 자동화할 수 없다.

#### 2. Memory Systems (메모리 시스템)
| 유형 | 특성 |
|---|---|
| **Short-term (Working)** | 즉각적 컨텍스트 버퍼; 인컨텍스트 학습 가능; 작업 연속성 지원 |
| **Long-term** | 외부 벡터 스토어; 빠른 히스토리 검색; 덜 일반적이지만 점점 중요해짐 |

메모리는 Agent가 도구로 수집한 정보를 저장/검색하여 반복적 개선을 가능하게 한다.

#### 3. Tool Utilization (도구 활용)
Agent는 외부 도구를 **언제, 어떻게** 사용할지 알아야 한다. 도구는 계획된 전략을 구체적인 결과로 연결한다.

#### 4. Perception (입력 처리)
- 모든 들어오는 정보, 사용자 입력, 환경 데이터를 처리
- Agent가 추론할 수 있는 형태로 변환
- 예: 텍스트 파싱(NLP), 음성-텍스트 변환, 컴퓨터 비전(카메라 피드)

#### 5. Context Engineering (컨텍스트 엔지니어링)
- **Context Offloading**: 정보를 외부 시스템으로 이동
- **Context Reduction**: 히스토리 압축
- **Context Retrieval**: 동적으로 정보 추가
- **Context Isolation**: 컨텍스트 분리

#### 6. Orchestration Engine (오케스트레이션 엔진)
- **Agent Harness**: 모델을 감싸는 소프트웨어
- 도구 호출 실행, 메시지 히스토리 루프 관리
- 컨텍스트 엔지니어링 로직 처리
- 모든 컴포넌트의 입출력 라우팅

LLM은 추론과 구조화된 "도구 호출"을 생성하지만, Harness가 실제 실행과 관리를 담당한다.

#### 7. Feedback & Evaluation (피드백 및 평가)
- **ReAct 프레임워크**: Thought, Action, Observation을 교차 실행
- 관찰 형태로 환경으로부터 피드백 수신
- 인간 및 모델 피드백
- 지속적 개선의 핵심

이 7가지 컴포넌트가 현대 LLM 기반 AI Agent의 아키텍처 백본을 형성한다.

### 7. 컨텍스트 엔지니어링 안티패턴

#### 과도한 컨텍스트 주입(Context Overflow)
- **증상**: 모든 가능한 정보를 컨텍스트에 포함시키려는 시도
- **문제점**: 토큰 비용 급증, 응답 지연 증가, 모델의 주의 분산, 핵심 정보 손실
- **해결책**: 관련성 필터링, 상위 N개 청크만 선택, 동적 컨텍스트 선택

#### 모호한 지시문과 충돌하는 컨텍스트
- **증상**: System Prompt와 Tool 정의가 상충되거나, 검색된 정보가 지시사항과 모순
- **문제점**: Agent가 일관되지 않은 행동을 보이거나 작업 실패
- **해결책**: 명확한 우선순위 계층 정의 (System Prompt > User Message > Retrieved Context), 충돌 감지 및 해결 메커니즘 구축

#### 컨텍스트 의존성 문제(Context Drift)
- **증상**: 대화가 길어지면서 초기 컨텍스트와 현재 컨텍스트가 괴리되는 현상
- **문제점**: Agent가 원래 목표를 잊거나 관련 없는 방향으로 진행
- **해결책**: 주기적인 컨텍스트 요약, 핵심 목표/제약사항의 지속적 리마인더, Episodic Memory를 통한 과거 컨텍스트 참조

#### 대형 컨텍스트 윈도우에 대한 오해
- **오해**: 200K-2M 토큰 컨텍스트 윈도우가 Agent 메모리 문제를 해결했다
- **현실**: 컨텍스트 윈도우는 작업 메모리일 뿐이며 장기 저장소가 아님
- **문제점**: 전체 대화 기록을 매 호출마다 주입하면 비용과 지연시간이 감당 불가능
- **해결책**: 외부 메모리 시스템(벡터 DB, 그래프 DB) + Dual-Layer Architecture

#### 모든 것을 컨텍스트에 덤프하기
- **증상**: 검색된 모든 문서, 전체 대화 기록, 모든 Tool 정의를 무분별하게 포함
- **문제점**: 노이즈 증가, 관련성 저하, 비용 낭비
- **해결책**: Memory Node를 통한 선별적 저장, Hot/Cold Path 분리, 관련성 기반 필터링

### 8. 실전 적용 사례

#### CLAUDE.md / AGENT.md를 활용한 프로젝트 컨텍스트 관리
- **CLAUDE.md**: 프로젝트별 지속적인 지시사항, 컨벤션, 제약사항을 정의하여 매 세션마다 반복 설명 불필요
- **AGENT.md**: 특정 Agent의 역할, 사용 가능한 도구, 권한 범위를 명시적으로 정의
- **장점**: 프로젝트 컨텍스트를 코드베이스의 일부로 버전 관리, 팀원 간 일관성 유지, 새로운 Agent 온보딩 시간 단축
- **구조화**: 프로젝트 개요 → 아키텍처 패턴 → 코딩 스타일 → 제약사항 → 도구 사용법 순으로 계층적 구성

#### Skills, Hooks를 통한 동적 컨텍스트 주입
- **Skills**: 재사용 가능한 작업 템플릿으로, 호출 시 관련 컨텍스트를 자동으로 구성
  - 예: `/commit` skill은 git 상태, 최근 커밋 메시지 스타일, 변경 사항을 자동으로 수집하여 컨텍스트 구성
- **Hooks**: 특정 이벤트(파일 저장, 명령 실행 전/후) 발생 시 컨텍스트를 동적으로 업데이트
  - 예: 파일 저장 시 린터 결과를 컨텍스트에 추가, 테스트 실행 전 관련 테스트 파일 자동 검색
- **효과**: 사용자가 명시적으로 요청하지 않아도 필요한 컨텍스트를 적시에 제공, 작업 흐름 단축

#### 대규모 코드베이스에서의 컨텍스트 전략

**도전 과제:**
- 수만 개의 파일 중 어떤 것이 현재 작업과 관련있는지 식별
- 컨텍스트 윈도우 제한 내에서 충분한 코드 이해도 확보
- 변경이 다른 부분에 미칠 영향 파악

**전략:**

1. **계층적 컨텍스트 구축**
   - Level 1: 프로젝트 개요 (README, CLAUDE.md)
   - Level 2: 모듈/패키지 구조 (디렉토리 트리, 주요 진입점)
   - Level 3: 관련 파일 (Glob, Grep으로 탐색)
   - Level 4: 세부 구현 (특정 함수/클래스)

2. **지식 그래프 기반 코드 탐색**
   - 클래스 상속 관계, 함수 호출 그래프, 의존성 트리를 사전 구축
   - 작업 시작 시 영향 범위를 그래프 쿼리로 빠르게 파악
   - 변경사항의 파급 효과를 그래프 순회로 예측

3. **Semantic Code Search**
   - 자연어 쿼리 → 임베딩 → 관련 코드 블록 검색
   - 예: "인증 토큰 검증 로직"이라는 쿼리로 관련 파일 직접 도달
   - 함수명이나 변수명을 모를 때 특히 유용

4. **Progressive Context Loading**
   - 필요한 만큼만 점진적으로 컨텍스트 로드
   - 초기에는 요약본 → 필요시 세부 내용 확장
   - Explore Agent 활용: 8개 이상의 파일/디렉토리 탐색이 필요한 경우 위임

5. **캐싱 & 인덱싱**
   - 자주 사용하는 유틸리티, 공통 패턴은 사전 인덱싱하여 빠른 접근
   - 검색 결과를 세션 단위로 캐싱하여 반복 쿼리 최적화

## 핵심 정리

### Anthropic의 핵심 원칙
**"원하는 결과의 가능성을 최대화하는 최소한의 고신호 토큰 세트를 찾는 것"**

컨텍스트 엔지니어링은 시스템 지시사항, 도구, MCP, 외부 데이터, 메시지 히스토리를 포함하여 LLM 추론 중 최적의 토큰 세트를 큐레이션하고 유지하는 전략이다.

### 패러다임 전환: 프롬프트에서 컨텍스트로
- 2026년 현재, AI Agent 개발의 핵심은 "어떻게 물을 것인가"에서 "무엇을 알게 할 것인가"로 이동
- 프롬프트 엔지니어링은 컨텍스트 엔지니어링의 하위 집합이며, 정보 아키텍처 전반을 다루는 더 포괄적인 접근이 필요
- **Agent의 간소화된 정의:** "도구를 자율적으로 사용하는 LLM의 루프"

### 대형 컨텍스트 윈도우의 한계와 Context Rot
- 200K-2M 토큰의 대형 윈도우가 등장했지만 이는 작업 메모리일 뿐
- **Context Rot 문제**: Transformer는 n개 토큰에 대해 n² 쌍별 관계 생성 → 컨텍스트가 길어질수록 검색 정밀도 감소, 장거리 추론 능력 저하
- LLM은 제한된 "주의 예산(Attention Budget)"을 가지며, 성능은 점진적으로 감소
- 프로덕션 Agent는 외부 메모리 시스템(벡터 DB, 그래프 DB, Episodic Memory) 필수
- Dual-Layer Architecture (Hot Path + Cold Path)가 2026년 표준

### 컨텍스트가 길어지면 성능이 떨어지는 7가지 이유
1. **주의 희석(Attention Dilution)**: Softmax attention이 희소 정보 토큰의 기여도를 소멸시킴
2. **이차 복잡도(Quadratic Complexity)**: O(n²) 복잡도로 계산/메모리가 이차적 증가 (10배 토큰 → 100배 컴퓨팅)
3. **Lost in the Middle**: 정보가 중간에 있을 때 30% 이상 성능 저하 (U자형 곡선)
4. **Know But Don't Tell**: 내부 인코딩과 출력 생성 간 단절
5. **Context Rot**: 비균일적, 작업 특정적 성능 저하
6. **스케일링 갭**: 컨텍스트 증가 시 개인화/프라이버시 능력 감소 (2026년 연구)
7. **아키텍처적 한계**: 엔지니어링 문제가 아닌 근본적 설계 한계

이것은 현재 LLM 연구의 가장 활발하고 중요한 미해결 과제 중 하나다.

### 컨텍스트 최적화의 핵심: 압축과 관련성
- 토큰 비용과 품질의 균형이 중요: 50-80% 토큰 절감 가능
- Relevance Filtering, Semantic Deduplication, Extractive Summarization 조합 활용
- RAG 시스템에서는 검색 품질과 컨텍스트 품질이 모두 중요

### 메모리 계층의 중요성
- Short-term (현재 작업), Long-term (세션 간 지속), Episodic/Semantic/Procedural (경험/지식/전략)
- Zep (Temporal Knowledge Graphs), Mem0 (사용자 선호도), PostgresSaver (체크포인트)가 핵심 도구
- Mem0는 전체 컨텍스트 방식 대비 91% 낮은 응답 시간 달성

### 안티패턴 경계
- 과도한 컨텍스트 주입 (Context Overflow)
- 모든 것을 컨텍스트에 덤프하기 (관련성 없는 정보 포함)
- 컨텍스트 윈도우만으로 메모리 문제를 해결하려는 시도

### 실전 적용의 핵심
- CLAUDE.md/AGENT.md로 프로젝트 컨텍스트를 코드베이스의 일부로 관리
- Skills/Hooks로 동적 컨텍스트 주입 자동화
- 대규모 코드베이스: 계층적 구축 + 지식 그래프 + Semantic Search + Progressive Loading

### 장기 작업을 위한 3가지 기법
1. **Compaction (압축)**: 대화 요약 후 재시작 - 앞뒤 대화가 필요한 작업에 최적
2. **Note-taking (노트 작성)**: 컨텍스트 윈도우 외부에 영구 노트 - 이정표가 있는 반복 개발에 최적
3. **Sub-agent**: 전문화된 서브 Agent로 작업 분할 - 복잡한 병렬 연구에 최적

### AI Agent의 7가지 핵심 컴포넌트
Planning, Memory, Tool Utilization, Perception, Context Engineering, Orchestration, Feedback이 시너지를 이루어 효과적인 Agent를 형성한다.

### System Prompt 설계의 "적절한 고도" 원칙
- Too Brittle (하드코딩된 if-else 논리)와 Too Vague (구체적 신호 없는 가이던스) 사이의 균형
- 행동을 안내할 만큼 구체적이면서도 강력한 휴리스틱을 제공할 만큼 유연해야 함
- 최소한으로 시작 → 테스트 → 실패 모드 기반 반복

## 키워드

### 컨텍스트 엔지니어링 (Context Engineering)
AI 모델이 응답을 생성할 때 접근할 수 있는 전체 정보 환경을 체계적으로 설계하고 관리하는 기법. 프롬프트 엔지니어링을 포함하는 더 포괄적인 개념으로, "어떻게 말할 것인가"가 아닌 "무엇을 알게 할 것인가"에 초점을 둔다.

### 프롬프트 엔지니어링 (Prompt Engineering)
특정 시점에 모델에게 지시하는 방법을 개선하는 기법. 텍스트 지시사항의 구조, 표현, 예시를 최적화하여 원하는 응답을 유도한다. 2026년 현재 컨텍스트 엔지니어링의 하위 집합으로 재정의되고 있다.

### 컨텍스트 윈도우 (Context Window)
LLM이 한 번에 처리할 수 있는 토큰의 최대 개수. Claude Opus 4.6(200K), GPT-5.2(400K), Gemini 3 Pro(2M) 등 대형 윈도우가 등장했지만, 이는 작업 메모리일 뿐 장기 저장소가 아니며 프로덕션 Agent에는 외부 메모리 시스템이 필수적이다.

### RAG (Retrieval-Augmented Generation)
LLM을 외부 데이터 소스에 연결하여 검색된 정보를 기반으로 응답을 생성하는 하이브리드 기술. 내부 학습 데이터에만 의존하지 않고 실시간, 전문화된 정보로 모델을 강화하여 환각(hallucination)을 줄이고 정확성을 높인다.

### 토큰 최적화 (Token Optimization)
LLM 호출 시 전송되는 토큰 수를 줄여 비용과 지연시간을 절감하는 기법. Relevance Filtering, Semantic Deduplication, Extractive Summarization 등의 압축 기법을 조합하여 50-80% 토큰 절감 가능. 품질 보존과 효율성 간의 균형이 핵심이다.

### System Prompt
Agent의 역할, 제약사항, 목표를 정의하는 고정된 지시사항. 모델의 일관된 톤, 스타일, 응답 형식을 보장하며, 프롬프트 엔지니어링의 핵심 요소이자 컨텍스트 엔지니어링의 구성 요소 중 하나이다.

### AI Agent
계획(plan), 관찰(observe), 행동(act)을 여러 단계에 걸쳐 수행하는 자율형 AI 시스템. 단순 대화형 챗봇과 달리 상태를 유지하고 순차적 의사결정을 수행하며, 구조화된 맞춤형 컨텍스트가 각 단계에서 필수적이다.

### Memory Management
AI Agent가 과거 상호작용을 기억하고 경험에서 학습할 수 있도록 정보를 저장하고 검색하는 시스템. Short-term (현재 작업), Long-term (세션 간 지속), Episodic/Semantic/Procedural (경험/지식/전략) 메모리로 계층화된다.

### Few-shot Learning
모델에게 작업 수행 방식의 예시를 제공하여 학습을 유도하는 기법. 예시의 개수, 다양성, 배치 순서가 성능에 영향을 미치며, 컨텍스트 윈도우 제약 내에서 효율적으로 배치해야 한다.

### Context Compression
모델에 도달하기 전에 중복되거나 관련 없는 저가치 콘텐츠를 제거하는 기법. Semantic Summarization, Extractive Summarization, Relevance Filtering, Sparse Attention 등의 방법을 활용하며, LLMLingua-style RL 방식으로 최대 20배 단축 가능하다.

### Context Rot (컨텍스트 부패)
입력 길이가 증가함에 따라 LLM 성능이 저하되는 현상. Transformer의 이차 복잡도, 주의 희석, 위치 편향 등이 복합적으로 작용하여 발생한다. 단순히 컨텍스트 윈도우를 늘리는 것만으로는 해결할 수 없는 아키텍처적 한계이다.

### Attention Dilution (주의 희석)
컨텍스트 길이가 증가하면 Softmax attention의 확률 질량이 더 얇게 분산되어, 희소한 정보 토큰의 기여도가 소멸되는 현상. LLM의 제한된 "주의 예산(Attention Budget)" 내에서 중요 정보의 영향력이 실질적으로 감소한다.

### Lost in the Middle
LLM이 입력 컨텍스트의 시작이나 끝에 있는 정보는 잘 활용하지만, 중간에 있는 정보는 제대로 활용하지 못하는 현상. U자형 성능 곡선을 보이며, 위치 변경만으로도 30% 이상 성능 저하가 발생할 수 있다. Stanford/UW 연구(Liu et al., 2024)에서 발견.

### Quadratic Complexity (이차 복잡도)
Transformer의 Self-Attention 메커니즘이 n개 토큰에 대해 n² 연산을 수행하는 문제. 토큰 수가 10배 증가하면 계산량이 약 100배 증가하여, 장문 컨텍스트 처리의 근본적 병목이 된다. FlashAttention, Sparse Attention, Linear Attention 등의 해결책이 연구되고 있다.

### Primacy Bias & Recency Bias
LLM이 컨텍스트의 시작 부분(primacy)과 끝 부분(recency)에 있는 정보에 더 높은 가중치를 부여하는 경향. "Lost in the Middle" 현상의 원인이며, 중간에 위치한 중요 정보가 무시될 수 있다.

## 참고 자료

### 핵심 문서 (Core Documentation)
- **[Anthropic - Effective context engineering for AI agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)** - Anthropic의 공식 컨텍스트 엔지니어링 가이드. System Prompt 설계, 도구 설계 원칙, 장기 작업 기법(Compaction, Note-taking, Sub-agent), Context Rot 문제 등을 다룸
- **[Prompt Engineering Guide - Agent Components](https://www.promptingguide.ai/agents/components)** - AI Agent의 3가지 핵심 능력(Planning, Tool Utilization, Memory)과 이들의 시너지에 대한 설명

### Long Context Performance Degradation (장문 컨텍스트 성능 저하)
- **[Liu et al. (2024) - Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/abs/2307.03172)** - Stanford/UW의 획기적 연구. U자형 성능 곡선, primacy/recency bias, "Lost in the Middle" 현상 발견. TACL 2024 게재
  - [ACL Anthology](https://aclanthology.org/2024.tacl-1.9/) | [MIT Press](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00638/119630/)
- **[Chroma Research - Context Rot: How Increasing Input Tokens Impacts LLM Performance](https://research.trychroma.com/context-rot)** - 입력 길이 증가가 LLM 성능에 미치는 영향 연구
- **[Understanding AI - Context rot: the emerging challenge](https://www.understandingai.org/p/context-rot-the-emerging-challenge)** - Context Rot이 LLM 진보를 저해할 수 있는 신흥 도전과제
- **[arXiv - Insights into LLM Long-Context Failures](https://arxiv.org/html/2406.14673v1)** - "Know But Don't Tell" 현상: Transformer가 알지만 말하지 않는 경우
- **[Quantum Zeitgeist - Longer AI Contexts Weaken Privacy And Accuracy](https://quantumzeitgeist.com/longer-ai-contexts-weaken-privacy-accuracy/)** - 2026년 Oxford/UCL/Alan Turing Institute 연구: 프라이버시 & 개인화 스케일링 갭
- **[Medium - Recursive Language Models: Breaking the Context Window Barrier](https://medium.com/@nishant.tyagi_47779/recursive-language-models-breaking-the-context-window-barrier-b3500a236e1c)** - MIT 2025 RLM 접근법

### Attention Complexity & Scaling Solutions (Attention 복잡도 & 스케일링 솔루션)
- **[Harm de Vries - In the long (context) run](https://www.harmdevries.com/post/context-length/)** - 컨텍스트 길이 스케일링의 실전 분석
- **[Machine Learning at Scale - Breaking the Attention Barrier](https://machinelearningatscale.substack.com/p/64-challenges-and-solutions-of-long)** - LLM 컨텍스트 길이 스케일링 심층 분석
- **[ICLR 2024 - Long-Context Attention in Near-Linear Time](https://proceedings.iclr.cc/paper_files/paper/2024/file/ab5aa940590399350401c57cdf52ce78-Paper-Conference.pdf)** - 거의 선형 시간의 장문 컨텍스트 attention 연구
- **[arXiv - Efficient Attention Mechanisms for Large Language Models: A Survey](https://arxiv.org/pdf/2507.19595)** - 효율적 attention 메커니즘 서베이
- **[arXiv - Scaling Context Requires Rethinking Attention](https://arxiv.org/html/2507.04239v1)** - 컨텍스트 스케일링은 attention 재고를 요구함
- **[Medium - LONGNET: Overcoming Quadratic Complexity with Dilated Attention](https://medium.com/@jain.sm/longnet-overcoming-quadratic-complexity-in-transformers-with-dilated-attention-for-long-sequence-763ee238819)** - Dilated Attention으로 이차 복잡도 극복

### Context Engineering vs Prompt Engineering
- [Elastic - Context engineering vs. prompt engineering](https://www.elastic.co/search-labs/blog/context-engineering-vs-prompt-engineering)
- [Neo4j - Why AI Teams Are Moving From Prompt Engineering to Context Engineering](https://neo4j.com/blog/agentic-ai/context-engineering-vs-prompt-engineering/)
- [Abstracta - Context Engineering vs Prompt Engineering](https://abstracta.us/blog/ai/context-engineering-vs-prompt-engineering/)
- [Glean - Context engineering vs. prompt engineering: Key differences explained](https://www.glean.com/perspectives/context-engineering-vs-prompt-engineering-key-differences-explained)
- [Sombra Inc. - AI Context Engineering in 2026: Why Prompt Engineering Is No Longer Enough](https://sombrainc.com/blog/ai-context-engineering-guide)
- [deepset - Context Engineering: The Next Frontier Beyond Prompt Engineering](https://www.deepset.ai/blog/context-engineering-the-next-frontier-beyond-prompt-engineering)

### RAG Best Practices
- [Prompt Engineering Guide - RAG for LLMs](https://www.promptingguide.ai/research/rag)
- [Google Cloud - RAG systems: Best practices to master evaluation](https://cloud.google.com/blog/products/ai-machine-learning/optimizing-rag-retrieval)
- [Stack Overflow - Practical tips for retrieval-augmented generation (RAG)](https://stackoverflow.blog/2024/08/15/practical-tips-for-retrieval-augmented-generation-rag/)
- [arXiv - Enhancing Retrieval-Augmented Generation: A Study of Best Practices](https://arxiv.org/abs/2501.07391)
- [Pinecone - Retrieval-Augmented Generation (RAG)](https://www.pinecone.io/learn/retrieval-augmented-generation/)

### AI Agent Memory Architecture
- [IBM - What Is AI Agent Memory?](https://www.ibm.com/think/topics/ai-agent-memory)
- [Redis - AI Agent Memory: Build Stateful AI Systems That Remember](https://redis.io/blog/ai-agent-memory-stateful-systems/)
- [AWS - Building smarter AI agents: AgentCore long-term memory deep dive](https://aws.amazon.com/blogs/machine-learning/building-smarter-ai-agents-agentcore-long-term-memory-deep-dive/)
- [MachineLearningMastery - Beyond Short-term Memory: The 3 Types of Long-term Memory AI Agents Need](https://machinelearningmastery.com/beyond-short-term-memory-the-3-types-of-long-term-memory-ai-agents-need/)
- [MarkTechPost - How to Build Memory-Driven AI Agents](https://www.marktechpost.com/2026/02/01/how-to-build-memory-driven-ai-agents-with-short-term-long-term-and-episodic-memory/)
- [Taskade - Types of AI Agent Memory Explained (2026)](https://www.taskade.com/blog/ai-agent-memory)

### Context Compression & Token Optimization
- [Medium - Token Efficiency and Compression Techniques in Large Language Models](https://medium.com/@anicomanesh/token-efficiency-and-compression-techniques-in-large-language-models-navigating-context-length-05a61283412b)
- [OneUpTime - How to Build Context Compression](https://oneuptime.com/blog/post/2026-01-30-context-compression/view)
- [MachineLearningMastery - Prompt Compression for LLM Generation Optimization](https://machinelearningmastery.com/prompt-compression-for-llm-generation-optimization-and-cost-reduction/)
- [agenta.ai - Top techniques to Manage Context Lengths in LLMs](https://agenta.ai/blog/top-6-techniques-to-manage-context-length-in-llms)
- [Maxim - Context Window Management Strategies](https://www.getmaxim.ai/articles/context-window-management-strategies-for-long-context-ai-agents-and-chatbots/)
- [GitHub - Awesome LLM Compression](https://github.com/HuangOwen/Awesome-LLM-Compression)
