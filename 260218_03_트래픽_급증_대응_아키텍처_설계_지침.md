# 트래픽 급증 대응 아키텍처 설계 지침

## 개요
무신사 이벤트, 수강신청 등 특정 시점에 트래픽이 급격히 증가하는 플랫폼에서의 대응 아키텍처 설계 전략과 지침. 트래픽 스파이크는 단순히 서버를 늘리는 것으로 해결할 수 없으며, Rate Limiting, Circuit Breaker, Virtual Waiting Room 등 가용성 아키텍처의 일부로 설계되어야 한다.

## 상세 내용

### 1. 트래픽 급증의 특성

#### 예측 가능한 급증 vs 예측 불가능한 급증

**예측 가능한 급증:**
- 플래시 세일, 티켓 오픈, 제품 론칭
- 규제 마감일, 수강신청, 아침 9시 러시
- **대응**: Predictive Pre-Warming - CronJob으로 이벤트 직전 Replica 사전 증설

**예측 불가능한 급증:**
- 바이럴 이벤트, 예상치 못한 언론 노출
- 급격한 사용자 유입
- **대응**: Reactive Auto-Scaling + Circuit Breaker + Virtual Waiting Room

#### 트래픽 패턴 분석

**스파이크(Spike):**
- 매우 짧은 시간(초-분) 동안 급격한 트래픽 증가
- 예: 플래시 세일 시작 직후 수초

**피크(Peak):**
- 일정 시간(분-시간) 동안 높은 트래픽 유지
- 예: 출퇴근 시간대, 점심시간

**서지(Surge):**
- 예상보다 높은 수준의 트래픽이 지속
- 예: 예상 1만 TPS → 실제 5만 TPS

#### 무신사/수강신청 등 실제 사례의 트래픽 특성

**무신사 특가 이벤트:**
- 이벤트 시작 시각에 극심한 스파이크 (수십만 명 동시 접속)
- 선착순 구매로 인한 동시성 제어 문제
- 재고 감소에 따른 락 경합

**수강신청:**
- 정해진 시각에 수만 명 동시 접속
- 좌석 제한으로 인한 경쟁 상황
- 실패 후 재시도로 인한 2차 스파이크

**Ticketmaster 사례:**
- 대규모 서버 보유에도 불구하고 Virtual Waiting Room 사용
- 대부분의 웹사이트에는 스케일로 해결 불가능한 **트랜잭션 한계**가 존재

### 2. 트래픽 제어 전략

#### Rate Limiting과 Throttling

**Rate Limiting:**
- API Gateway 레벨에서 용량을 초과하는 로드를 즉시 차단
- 정상 요청은 정상적으로 진행
- 독립성이 강점이자 취약점인 분산 시스템에서 필수

**Throttling:**
- 요청을 거부하는 대신 속도를 늦춤
- 큐에 넣어 순차 처리
- Rate Limiting보다 사용자 경험 개선

**중요성:**
- 한 서비스가 실패하기 시작하면 전체 생태계를 무너뜨릴 수 있는 ripple effect 발생
- Traffic Control 없이 Auto-Scaling만 하면 해결 불가능한 문제에 리소스만 낭비
- 수백 개의 인스턴스가 홍수와 무의미하게 싸우며 비용만 폭증

#### 대기열 기반 트래픽 관리 (Virtual Waiting Room)

**Virtual Waiting Room (VWR)의 핵심 역할:**

기존의 로드 밸런싱, 오토스케일링, 정적 Rate Limiting과 달리, VWR은 **동적 게이팅 메커니즘**을 도입하여 사용자 트래픽을 백엔드 서비스로부터 분리한다.

**핵심 동작:**
1. **초과 수요 빠르고 일관되게 식별**
2. **사용자 위치 손실 없이 제어된 상태로 보류**
3. **예측 가능하고 조정 가능한 속도로 사용자 방출**
4. **보호하려는 시스템의 로드를 증폭시키지 않으면서 수행**

**건강한 대기열의 특징:**
- 사용자를 **빠르게** 입장시키는 것이 아니라 **예측 가능하게** 입장시킴

**아키텍처 구성 요소:**
- **Edge-Level Interception Layer**: CDN, Reverse Proxy, DNS 리다이렉션
- **Centralized Queue Management Service**: 중앙 집중식 큐 관리
- **Token-Based User Identification**: 사용자 추적 모듈
- **Policy Engine**: 큐 로직 및 방출 임계값 결정

**Queue Configuration (완전 프로그래밍 가능):**
- 백엔드 서버 로드
- 의심스러운 방문자 패턴
- 방문자 임계값
- 지리적 지역
- 트래픽 스파이크 경고
- 기타 정의된 조건

**Cloudflare Waiting Room 예시:**
- 사용자가 앱 떠나거나 쿠키 만료 시 즉시 새 사용자 입장
- 활성화 임계값: 유입 트래픽 속도 또는 총 활성 사용자 기반
- 큐잉 옵션: FIFO, Random, Lottery

**장점:**
- 서비스 충돌 방지, 공정성 보장, 사용자 경험 유지
- 대규모 인프라 투자 없이 비용 효과적이고 확장 가능
- 급격한 수요에 유연하게 적응
- 사이트 오류나 충돌 대신 큐에 참여

**가용성 아키텍처의 일부:**
- Waiting Room은 CDN 기능, 서드파티 제공자, 커스텀 Admission Service로 구현 가능
- 역할은 동일: **가용성 아키텍처의 일부**가 됨

#### Token Bucket / Leaky Bucket 알고리즘

**Token Bucket:**
- 고정 용량의 버킷, 고정 속도로 토큰 추가
- 요청 시 토큰 소비, 토큰 없으면 대기 또는 거부
- **버스트 허용**: 버킷이 가득 차면 일시적 스파이크 처리 가능

**Leaky Bucket:**
- 고정 속도로 요청 처리 (누수)
- 버킷이 가득 차면 초과 요청 드롭
- **평활화**: 트래픽을 일정한 속도로 변환

**선택 가이드:**
- 일시적 버스트 허용 필요 → Token Bucket
- 엄격한 속도 제한 필요 → Leaky Bucket

#### Circuit Breaker 패턴

**3가지 상태:**
1. **Closed (폐쇄)**: 정상 작동, 모든 요청 통과
2. **Open (개방)**: 실패 임계값 도달, 모든 요청 즉시 거부
3. **Half-Open (반개방)**: 타임아웃 후 테스트 요청 허용, 성공 시 Closed로 전환

**핵심 이점:**
- **Fail Fast**: 리소스 고갈 방지, 개방 회로가 불필요한 요청 차단
- **Automatic Recovery**: Half-Open 상태가 서비스 복구 테스트
- **Fallback 필수**: 항상 성능 저하 모드 준비
- **Monitor Everything**: 회로 상태 추적으로 시스템 건강도 파악

**다른 패턴과 결합:**
- **Decorator 순서 중요**: Retry → Circuit Breaker → Timeout
- **주의**: 대상 서비스가 과부하라면 재시도는 문제를 악화시킴
- **해결**: Exponential Backoff 또는 Circuit Breaker와 결합하여 DoS 공격으로 변질 방지

**2026년 권장 도구:**
- **Resilience4j** (Java): v2.2.0, 현대적이고 활발히 유지관리
- **Polly** (.NET): Circuit Breaker, Retry, Timeout 지원
- **Istio** (Service Mesh): v1.16.0, 네트워크 레벨 Circuit Breaker (코드 수정 불필요)

### 3. 캐싱 전략

#### CDN 캐싱 (정적 리소스)

- 정적 자산(이미지, CSS, JS)을 엣지에 배포
- 원본 서버 로드 감소, 지연시간 단축
- CloudFront, Cloudflare, Fastly 등

#### 애플리케이션 레벨 캐싱 (Redis, Memcached)

**Redis:**
- In-memory Key-Value Store
- Persistence 지원 (RDB, AOF)
- Pub/Sub, Sorted Set 등 고급 자료구조

**Memcached:**
- 순수 캐싱에 최적화
- 멀티스레드 지원
- 단순하고 빠름

#### Cache Stampede (Thundering Herd) 방지

**문제:**
- 캐시 만료 시 수천 개의 동시 요청이 모두 백엔드에 도달
- 백엔드가 동일한 비용이 큰 요청을 동시에 수행
- 시스템 과부하 및 성능 저하

**해결책:**

**1. Distributed Locking (분산 락)**
```redis
SET key value EX timeout NX  # Atomic lock acquisition
```
- **주의**: 락 타임아웃 > 계산 시간 (2초 쿼리면 락 타임아웃 최소 3초)

**2. Probabilistic Early Recomputation (확률적 조기 재계산)**
- 만료 전에 사전에 재계산
- 확률 기반으로 일부 요청만 재계산 수행

**3. Request Coalescing (요청 병합)**
- 동일한 키에 대한 동시 요청을 단일 백엔드 쿼리로 병합
- 첫 요청이 계산 중이면 다른 요청은 대기

**일반적인 함정:**
- **TTL 너무 짧게 설정**: Stampede 빈도 증가
- **Clock Skew 무시**: 분산 시스템에서 조기 만료 계산이 예상 외로 동작
- **Cold Start**: 새 버전 배포 또는 스케일업 시 캐시 비어있음 → Cache Warming 또는 조정된 배포
- **과도한 엔지니어링**: 모든 캐시 키가 Stampede 보호 필요한 것은 아님 (Hot Key만)

#### Cache 패턴

**Cache-Aside (Lazy Loading):**
```
if cache.get(key):
    return cache.get(key)
else:
    data = db.query(...)
    cache.set(key, data)
    return data
```

**Write-Through:**
- 쓰기 시 DB + Cache 동시 업데이트
- 데이터 일관성 보장, 쓰기 지연 증가

**Write-Behind (Write-Back):**
- Cache에 먼저 쓰고 비동기로 DB 업데이트
- 쓰기 성능 최적화, 데이터 손실 위험

**모범 사례 (2026):**
- **Stampede 보호는 필수**: Hot Key에 Single-Flight Request Coalescing + TTL Jitter
- **Never Delete Before Computing**: 업데이트 중 캐시가 비어있지 않도록 Atomic Swap 패턴
- **Monitor Continuously**: Hit Rate, Error Rate, Latency 추적
- **Design for Degradation**: 실패보다 Stale Data 제공; 가용성 > 일관성

### 4. 메시지 큐 기반 비동기 처리

#### 동기 → 비동기 전환 전략

**동기 처리의 문제:**
- 클라이언트가 응답을 기다리며 리소스 점유
- 트래픽 급증 시 서비스 과부하

**비동기 전환:**
```
Before: Client → API → DB (Synchronous, blocking)
After:  Client → API → Queue → Worker → DB (Asynchronous, non-blocking)
```

**장점:**
- API는 즉시 응답 (202 Accepted + Job ID)
- Worker가 자신의 속도로 처리
- 부하 스파이크를 큐가 버퍼링

#### Kafka / RabbitMQ 비교 및 활용

| 차원 | Kafka | RabbitMQ |
|---|---|---|
| **주요 용도** | 고처리량 스트리밍 | 유연한 메시지 큐잉 |
| **Consumer 모델** | Pull-based | Push-based |
| **메시지 보존** | 설정 가능 (영구 로그) | 소비 후 삭제 |
| **지연시간** | 대규모에서 낮음 | 소규모에서 밀리초 미만 |
| **라우팅** | 파티션 기반 | 복잡한 Exchange 라우팅 |
| **백프레셔** | 대규모에서 자연스럽게 처리 | 큐 백업 시 성능 저하 |

**Kafka:**
- **"Dumb Broker, Smart Consumer"** 모델
- 데이터를 연속 커밋 로그로 처리
- Pull-based: Consumer가 자신의 offset 추적
- **대규모 처리량 및 재생 가능성**에 최적화
- 파티션 레벨에서 강력한 순서 보장
- **KRaft** (Kafka Raft Metadata mode) 도입 (2024/2025): 단일 바이너리 배포로 운영 간소화

**RabbitMQ:**
- **"Smart Broker, Dumb Consumer"** 모델
- 복잡한 라우팅 로직: Direct, Topic, Fanout, Header Exchange
- 소비 후 메시지 일반적으로 삭제
- **마이크로서비스 오케스트레이션**에 탁월
- LAN 내부에서 밀리초 미만 지연시간
- **Quorum Queues** (Raft 합의 알고리즘, 2025년 기본): Split-brain 문제 해결, 강력한 일관성

**사용 사례:**
- **Kafka**: 실시간 데이터 스트리밍, 이벤트 기반 아키텍처, 분산 데이터 처리, 재생 가능성 필요
- **RabbitMQ**: 단순한 내부 마이크로서비스 메시징 (명령, 이벤트, 백그라운드 작업), 복잡한 라우팅

**함께 사용:**
- 전자상거래: 주문 시 **Kafka**가 분석/모니터링용 이벤트 캡처, **RabbitMQ**가 결제 서비스 트랜잭션 큐잉
- 실시간 인사이트 + 비즈니스 크리티컬 운영 안정성

#### 이벤트 기반 아키텍처 (Event-Driven Architecture)

**EDA 개념:**
- 상태 변화나 업데이트를 이벤트로 표현
- 서비스가 직접 요청 대신 이벤트에 비동기적으로 반응
- 컴포넌트 분리, 유연성, 확장성, 복원력 제공

**핵심 이점:**
- 서비스가 관심 있는 메시지를 **자신의 속도로 소비** (Backpressure)
- HTTP 호출의 파도로 압도되는 일 방지

#### 백프레셔(Backpressure) 관리

**Backpressure란:**
- 다운스트림 컴포넌트가 처리 속도를 조절하여 업스트림에 신호를 보내는 메커니즘
- 메시지 브로커가 로드 스파이크를 버퍼링하여 API 보호

**RabbitMQ 주의사항:**
- 큐가 백업되기 시작하면 성능이 크게 저하
- "Firehose" 시나리오에는 부적합

**Kafka 강점:**
- 대규모에서 백프레셔를 자연스럽게 처리
- Consumer가 자신의 속도로 Pull

### 5. 오토 스케일링과 인프라

#### Horizontal Scaling vs Vertical Scaling

**Horizontal Scaling (수평 확장):**
- 동일한 인스턴스를 더 많이 추가
- 무한히 확장 가능 (이론상)
- 로드 밸런서 필요
- **권장**: 상태 비저장(Stateless) 서비스

**Vertical Scaling (수직 확장):**
- 단일 인스턴스의 CPU/메모리 증가
- 물리적 한계 존재
- 다운타임 발생 가능
- 특정 워크로드(DB, 캐시)에 유용

#### Kubernetes Auto-Scaling 메커니즘

**HPA (Horizontal Pod Autoscaler):**
- CPU, 메모리, 커스텀 메트릭 기반으로 Pod 수 자동 조정
- Metrics Server 통해 지속적으로 모니터링
- 임계값 초과 시 Pod 증감

**VPA (Vertical Pod Autoscaler):**
- 개별 Pod의 CPU/메모리 요청/한계 조정
- HPA가 Scale-Out이라면 VPA는 Scale-Up
- Pod 재시작 가능 (주의)

**KEDA (Kubernetes Event-Driven Autoscaling):**
- 외부 이벤트 소스 모니터링하여 동적 스케일링
- HPA는 CPU/메모리 위주, KEDA는 실시간 이벤트 기반
- **Zero Replica 스케일링** 지원: 유휴 시 리소스 소비 없음 → 비용 절감
- Kafka Lag, SQS 백로그, HTTP 요청 등 다양한 Scaler

**Cluster Autoscaler:**
- 노드 레벨 탄력성
- Pod가 스케줄링 불가능하면 노드 추가

#### Auto Scaling 설계 모범 사례

**1. 워크로드에 맞는 Scaler 선택:**
- 예측 가능한 트래픽 → CPU/메모리 기반
- 급격한 버스트/외부 이벤트 → 커스텀 메트릭 또는 KEDA

**2. 예측적 Pre-Warming (알려진 트래픽 스파이크):**
```yaml
apiVersion: batch/v1
kind: CronJob
spec:
  schedule: "55 8 * * *"  # 9AM rush 5분 전
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: scale-up
            image: kubectl
            command: ["kubectl", "scale", "deployment/myapp", "--replicas=50"]
```

**3. Buffer Nodes 유지:**
- Cluster Auto-Scaling은 지연 발생 (노드 프로비저닝 시간)
- 사전 예열된 버퍼 노드 풀 유지하여 즉시 활성화
- 안정화 후 Cluster Autoscaler가 장기 노드 추가

**4. Stateless, Burst-Tolerant 서비스 설계:**
- Auto-Scaler는 만능이 아님
- 서비스가 Stateless가 아니거나 버스트 트래픽을 우아하게 처리하지 못하면 소용없음

**5. HPA와 VPA 분리:**
- 서로 다른 메트릭 기반 스케일링
- 예: HPA는 지연시간 기반, VPA는 메모리 기반

**6. Health Check 올바르게 구성:**
- 스케일링 전 기존 인스턴스가 건강하고 추가 로드 처리 가능한지 확인
- Liveness Probe + Readiness Probe

**7. Pod Disruption Budget 설정:**
- VPA 또는 Cluster Autoscaling 사용 시 동시에 제거/재시작 가능한 Pod 수 제어
- 다운타임 최소화

**8. Readiness Probe 최적화:**
- 실제 서비스 가용성 반영 (일반 Health Check 아님)
- 잘못 구성 시 초기화 중인 Pod로 트래픽 라우팅 → 실패 요청

#### 함정 피하기

- **느린 컨테이너 Warm-Up**: 앱은 빠르게 스케일링해도 컨테이너 부팅이 오래 걸리면 타임아웃
- **HPA 반응 지연**: HPA는 즉각적이지 않음 - 메트릭이 긴 파이프라인을 거침
- **공격적 임계값**: 너무 빠르거나 자주 스케일링하면 리소스 낭비. 보수적으로 시작 후 반복
- **Over-/Under-Scaling**: Over-Scaling = 리소스 낭비 + 비용, Under-Scaling = 성능 병목

#### 서버리스 아키텍처 활용

**AWS Lambda / Google Cloud Functions:**
- 이벤트 기반 자동 스케일링
- 사용한 만큼만 비용 (Pay-per-Execution)
- Cold Start 지연 주의

**사용 사례:**
- 이미지 처리, 데이터 변환
- Webhook 처리
- 예측 불가능한 트래픽 패턴

### 6. 데이터베이스 부하 분산

#### Read Replica 전략
- Master(Write) + Replica(Read) 분리
- 읽기 트래픽을 여러 Replica로 분산
- 비동기 복제 지연(Replication Lag) 고려

#### Connection Pool 튜닝
- Pool Size = (Core Count × 2) + Effective Spindle Count (일반 가이드)
- Max Pool Size 너무 크면 DB 리소스 고갈
- 모니터링: Active Connections, Wait Time

#### Database Sharding
- 데이터를 여러 DB 인스턴스로 수평 분할
- Shard Key 선택 중요 (균등 분산)
- 복잡도 증가: JOIN 제한, 트랜잭션 관리 어려움

#### CQRS (Command Query Responsibility Segregation)
- Command (Write) 모델과 Query (Read) 모델 분리
- Write는 정규화된 DB, Read는 비정규화된 Read Model (Materialized View, Elasticsearch 등)
- 이벤트 소싱과 결합 시 강력

#### 비관적 락 vs 낙관적 락

**비관적 락 (Pessimistic Lock):**
- 트랜잭션 시작 시 락 획득
- 경합 많을 때 안전하지만 성능 저하
- `SELECT ... FOR UPDATE`

**낙관적 락 (Optimistic Lock):**
- Version/Timestamp 필드 사용
- 커밋 시 충돌 감지 → 재시도
- 경합 적을 때 높은 성능

### 7. 장애 대응과 회복력(Resilience)

#### Graceful Degradation (점진적 성능 저하)
- 핵심 기능 유지, 부가 기능 비활성화
- 예: 추천 시스템 실패 시 인기 상품 표시

#### Bulkhead 패턴 (격리)
- 리소스 풀을 격리하여 장애 전파 방지
- 컨테이너, 스레드 풀, Connection Pool 격리

#### Retry + Exponential Backoff
```python
for retry in range(max_retries):
    try:
        return api_call()
    except TransientError:
        time.sleep(2 ** retry + random.uniform(0, 1))  # Jitter 추가
```

#### Fallback 전략
- Primary 실패 시 Secondary로 전환
- Cache → DB → Static Response 순서

#### Health Check와 모니터링
- Liveness Probe: 프로세스 살아있는지
- Readiness Probe: 트래픽 받을 준비 되었는지
- APM, 로그, 메트릭, 분산 트레이싱

### 8. 실전 설계: 수강신청/이벤트 시스템

#### 선착순 처리 아키텍처
```
User Request
    ↓
[CDN / Edge Cache] - 정적 리소스
    ↓
[Virtual Waiting Room] - 트래픽 게이팅
    ↓
[API Gateway + Rate Limiting] - 요청 제어
    ↓
[Message Queue] - 요청 버퍼링
    ↓
[Worker Pool] - 좌석/재고 처리 (낙관적 락)
    ↓
[Database] - 트랜잭션 커밋
    ↓
[Notification Service] - 결과 알림
```

#### 재고/좌석 관리 동시성 제어

**Optimistic Lock with Version:**
```sql
UPDATE seats
SET is_reserved = true, version = version + 1
WHERE seat_id = ? AND version = ? AND is_reserved = false
```
- 실패 시 재시도 (Max 3회)

**Redis를 통한 사전 필터링:**
```python
if redis.decr(f"seat_count:{course_id}") >= 0:
    # DB에 실제 예약 시도
else:
    redis.incr(f"seat_count:{course_id}")  # Rollback
    return "SOLD_OUT"
```

#### 대기열 → 처리 → 결과 알림 파이프라인

1. **대기열**: Virtual Waiting Room 또는 Kafka Queue
2. **처리**: Worker가 FIFO 순서로 소비, DB 트랜잭션 수행
3. **알림**: WebSocket, SSE, 또는 Polling으로 결과 전달

#### 부하 테스트와 카오스 엔지니어링

**부하 테스트 도구:**
- **K6**, **Locust**: 트래픽 스파이크 시뮬레이션
- 목표 TPS의 150% 이상 테스트

**카오스 엔지니어링:**
- Chaos Monkey: 랜덤 인스턴스 종료
- 네트워크 지연/패킷 손실 주입
- DB 장애 시뮬레이션

**관찰 사항:**
- HPA 반응 시간
- Circuit Breaker 동작
- Graceful Degradation 효과

## 핵심 정리

### 트래픽 급증은 스케일만으로 해결 불가능
- Ticketmaster도 대규모 서버 보유에도 Virtual Waiting Room 사용
- 트랜잭션 한계는 스케일로 해결 불가 → 가용성 아키텍처 필수

### Layer 전략: 트래픽 제어의 계층화
1. **Edge**: CDN 캐싱, DDoS 보호
2. **Gate**: Virtual Waiting Room, Rate Limiting
3. **Process**: Circuit Breaker, 비동기 큐
4. **Store**: DB Read Replica, Connection Pool, CQRS

### Virtual Waiting Room은 필수 가용성 컴포넌트
- 건강한 대기열은 빠르게가 아니라 **예측 가능하게** 입장
- 동적 게이팅으로 사용자 트래픽을 백엔드에서 분리
- CDN, 서드파티, 커스텀 Admission Service로 구현

### Auto-Scaling의 황금률: 전략 조합
- **HPA**: 메트릭 기반 Pod 스케일링
- **VPA**: 리소스 Right-Sizing
- **KEDA**: 이벤트 기반 + 큐 기반 스케일링 + Zero Replica
- **Cluster Autoscaler**: 노드 레벨 탄력성
- **Pre-Warming + Buffer Nodes**: 예측 가능한 스파이크 대응

### Circuit Breaker + Retry는 필수 조합
- Decorator 순서: Retry → Circuit Breaker → Timeout
- Fail Fast로 리소스 고갈 방지
- Fallback 항상 준비 (Stale Cache > 실패)

### Cache Stampede 보호는 Hot Key 필수
- Distributed Locking (락 타임아웃 > 계산 시간)
- Request Coalescing
- TTL Jitter
- 삭제 전 계산 (Atomic Swap)

### Kafka vs RabbitMQ 선택 기준
- **Kafka**: 고처리량 스트리밍, 재생 가능성, 대규모
- **RabbitMQ**: 마이크로서비스 메시징, 복잡한 라우팅, 낮은 지연
- **함께 사용**: Analytics(Kafka) + Critical Messaging(RabbitMQ)

### 실전 시스템 설계의 핵심
- Virtual Waiting Room → API Gateway (Rate Limiting) → Queue (Buffer) → Worker (Optimistic Lock) → DB → Notification
- Redis로 사전 필터링하여 DB 부하 감소
- 부하 테스트 + 카오스 엔지니어링으로 검증

## 키워드

### 트래픽 급증 (Traffic Surge)
특정 시점에 평소보다 훨씬 많은 요청이 몰리는 현상. 플래시 세일, 티켓 오픈, 수강신청 등이 대표적이며, 단순 스케일링만으로는 해결 불가능한 트랜잭션 한계가 존재한다. Virtual Waiting Room, Rate Limiting, Circuit Breaker 등 가용성 아키텍처가 필수적이다.

### Rate Limiting (속도 제한)
API Gateway 레벨에서 용량을 초과하는 요청을 즉시 차단하는 메커니즘. Token Bucket, Leaky Bucket 알고리즘을 사용하며, 정상 요청은 통과하고 초과 요청은 거부하여 백엔드 시스템을 보호한다.

### 대기열 시스템 (Virtual Waiting Room)
트래픽 스파이크 시 사용자 트래픽을 백엔드 서비스로부터 분리하는 동적 게이팅 메커니즘. 건강한 대기열은 사용자를 빠르게가 아니라 예측 가능하게 입장시키며, Cloudflare, AWS Virtual Waiting Room, 커스텀 Admission Service로 구현 가능하다.

### Auto Scaling (자동 확장)
워크로드에 따라 리소스를 자동으로 증감하는 메커니즘. Kubernetes에서는 HPA(Pod 수), VPA(리소스 크기), KEDA(이벤트 기반), Cluster Autoscaler(노드)를 조합하며, 예측 가능한 스파이크는 Pre-Warming + Buffer Nodes로 대응한다.

### 캐싱 전략 (Caching Strategy)
반복적으로 요청되는 데이터를 빠른 저장소에 보관하여 백엔드 부하를 감소시키는 기법. CDN 캐싱(정적 리소스), Redis/Memcached(애플리케이션 레벨), Cache-Aside/Write-Through/Write-Behind 패턴이 있으며, Cache Stampede 보호가 Hot Key에 필수적이다.

### 비동기 처리 (Asynchronous Processing)
클라이언트가 응답을 기다리지 않고 즉시 리턴받은 후, 백엔드가 Queue를 통해 작업을 처리하는 패턴. Kafka/RabbitMQ로 요청을 버퍼링하여 부하 스파이크를 흡수하고, Worker가 자신의 속도로 처리한다. EDA(Event-Driven Architecture)의 핵심이다.

### Circuit Breaker (회로 차단기)
서비스 실패 시 요청을 즉시 차단하여 리소스 고갈을 방지하는 패턴. Closed(정상) → Open(차단) → Half-Open(테스트) 3가지 상태를 가지며, Resilience4j, Polly, Istio로 구현한다. Retry + Exponential Backoff와 결합하여 DoS 공격 방지.

### Graceful Degradation (점진적 성능 저하)
시스템 일부 실패 시 핵심 기능은 유지하고 부가 기능만 비활성화하는 복원력 패턴. 추천 시스템 실패 시 인기 상품 표시, Cache 실패 시 Stale Data 제공 등 가용성을 일관성보다 우선시한다.

### CQRS (Command Query Responsibility Segregation)
Command(Write) 모델과 Query(Read) 모델을 분리하는 패턴. Write는 정규화된 DB, Read는 비정규화된 Read Model(Materialized View, Elasticsearch)을 사용하여 읽기 성능을 최적화한다. Event Sourcing과 결합 시 강력하다.

### 부하 테스트 (Load Testing)
K6, Locust 등으로 트래픽 스파이크를 시뮬레이션하여 시스템의 처리 한계를 파악하고 병목 지점을 발견하는 테스트. 목표 TPS의 150% 이상 테스트하며, Chaos Engineering과 결합하여 장애 상황에서의 복원력도 검증한다.

## 참고 자료

### Virtual Waiting Room & Rate Limiting
- [LoadView - Virtual Waiting Room Load Testing](https://www.loadview-testing.com/blog/virtual-waiting-room-load-testing/) - 극심한 수요에 대한 대기열 로드 테스팅
- [Cloudflare Waiting Room](https://www.cloudflare.com/application-services/products/waiting-room/) - 동적 트래픽 관리 및 대기열 시스템
- [AWS - Virtual Waiting Room Architecture](https://docs.aws.amazon.com/solutions/latest/virtual-waiting-room-on-aws/architecture-overview.html) - AWS 공식 VWR 아키텍처 문서
- [Macrometa - How to Manage Traffic Surge](https://www.macrometa.com/blog/traffic-surge) - 트래픽 급증 관리 가이드
- [CrowdHandler - Website Performance Optimization](https://www.crowdhandler.com/blog/website-performance-optimization-a-guide-to-handling-high-traffic-loads) - 고트래픽 처리 가이드
- [Substack - Surviving Traffic Surge with Rate Limiting](https://yurimelo.substack.com/p/surviving-the-traffic-surge-why-rate) - 마이크로서비스에서의 Rate Limiting + Circuit Breaker

### Kubernetes Auto-Scaling
- [ScaleOps - Kubernetes Autoscaling Guide](https://scaleops.com/blog/kubernetes-autoscaling/) - Kubernetes Auto-Scaling 이점, 도전과제, 모범 사례
- [Codefresh - 5 Types of Kubernetes Autoscaling](https://codefresh.io/learn/kubernetes-management/5-types-of-kubernetes-autoscaling-pros-cons-advanced-methods/) - 5가지 Auto-Scaling 유형과 장단점
- [KEDA](https://keda.sh/) - Kubernetes Event-Driven Autoscaling 공식 문서
- [ScaleOps - Kubernetes HPA Best Practices](https://scaleops.com/blog/kubernetes-hpa/) - HPA 사용 사례, 한계, 모범 사례
- [Microsoft Learn - AKS Scaling Options](https://learn.microsoft.com/en-us/azure/aks/concepts-scale) - Azure Kubernetes Service 스케일링 옵션
- [Zeet - Kubernetes Scaling Guide](https://zeet.co/blog/master-kubernetes-scaling-expert-tips-for-hpa-vpa-cluster-autoscaling-and-more) - HPA, VPA, Cluster Autoscaling 전문가 팁
- [CloudRaft - Scaling in Kubernetes for Production](https://www.cloudraft.io/blog/kubernetes-autoscaling) - 프로덕션 워크로드를 위한 HPA, VPA, KEDA 가이드

### Cache Stampede & Circuit Breaker
- [OneUpTime - Cache Stampede Prevention](https://oneuptime.com/blog/post/2026-01-30-cache-stampede-prevention/view) - Cache Stampede 방지 구축 가이드 (2026)
- [OneUpTime - Circuit Breaker Patterns](https://oneuptime.com/blog/post/2026-02-02-circuit-breaker-patterns/view) - Circuit Breaker 패턴 구성 가이드 (2026)
- [OneUpTime - Circuit Breakers with Resilience4j](https://oneuptime.com/blog/post/2026-01-25-circuit-breakers-resilience4j-spring/view) - Spring Resilience4j Circuit Breaker 구현
- [DasRoot - Building Resilient Systems](https://dasroot.net/posts/2026/01/building-resilient-systems-circuit-breakers-retry-patterns/) - Circuit Breaker 및 Retry 패턴 (2026)
- [Talent500 - Circuit Breaker Pattern in Microservices](https://talent500.com/blog/circuit-breaker-pattern-microservices-design-best-practices/) - 마이크로서비스 Circuit Breaker 디자인 패턴
- [GeeksforGeeks - Circuit Breaker Pattern](https://www.geeksforgeeks.org/system-design/what-is-circuit-breaker-pattern-in-microservices/) - Circuit Breaker 패턴 설명
- [CodeCentric - Resilience Design Patterns](https://www.codecentric.de/en/knowledge-hub/blog/resilience-design-patterns-retry-fallback-timeout-circuit-breaker) - Retry, Fallback, Timeout, Circuit Breaker
- [Medium - Critical Caching Patterns](https://medium.com/@rachoork/critical-caching-patterns-preventing-catastrophic-failures-at-scale-ddc75ac0e863) - 대규모 장애 방지를 위한 캐싱 패턴

### Message Queue & Event-Driven Architecture
- [Quix - Apache Kafka vs RabbitMQ Comparison](https://quix.io/blog/apache-kafka-vs-rabbitmq-comparison) - 아키텍처, 기능, 사용 사례 비교
- [DataCamp - Kafka vs RabbitMQ](https://www.datacamp.com/blog/kafka-vs-rabbitmq) - 주요 차이점 및 사용 시점
- [DoubleCloud - Kafka vs RabbitMQ Features](https://double.cloud/blog/posts/2023/03/apache-kafka-vs-rabbitmq/) - 기능, 성능, 사용 사례 탐구
- [Confluent - Benchmarking RabbitMQ vs Kafka vs Pulsar](https://www.confluent.io/blog/kafka-fastest-messaging-system/) - 성능 벤치마크
- [Java Code Geeks - Event-Driven Architecture Decision Framework](https://www.javacodegeeks.com/2025/12/event-driven-architecture-kafka-vs-rabbitmq-vs-pulsar-a-2025-decision-framework.html) - 2025년 결정 프레임워크
- [DZone - Kafka and RabbitMQ for Scalable Systems](https://dzone.com/articles/event-driven-microservices-kafka-rabbitmq) - 확장 가능한 시스템 구축
- [Gigson - Event Driven Architecture Guide](https://www.gigson.co/blog/event-driven-architecture-using-apache-kafka-and-rabbitmq) - Apache Kafka와 RabbitMQ 완전 가이드
