# 수강신청 시스템에서 초당 10,000건의 요청 처리 아키텍처

## 개요
수강신청 시스템은 특정 시간에 대량의 트래픽이 집중되는 대표적인 **순간 폭주(Flash Crowd)** 시스템입니다. 수만 명의 학생이 동시에 같은 과목에 신청하면서 초당 10,000건 이상의 요청이 몰리면, 일반적인 아키텍처로는 DB 커넥션 고갈, 락 경합, 서버 과부하 등 다양한 병목이 발생합니다. 이 글에서는 구체적인 병목 지점을 단계별로 분석하고, 각 병목을 해결하기 위한 아키텍처 전략을 상세히 다룹니다.

## 상세 내용

### 1. 요청 흐름과 병목 발생 지점

수강신청의 전형적인 요청 흐름은 다음과 같습니다:

```
사용자 브라우저 → CDN/LB → WAS → DB
```

각 구간별로 병목이 발생할 수 있습니다:

```
[클라이언트] ----(1)---- [로드밸런서] ----(2)---- [WAS 서버] ----(3)--- [DB]
     │                    │                     │                  │
     │                    │                     │                  │
  중복 클릭             커넥션 한계            스레드 풀 고갈            락 경합
  새로고침 폭주         SSL 핸드셰이크             GC 멈춤            커넥션 풀 고갈
                       세션 고정              메모리 부족           슬로우 쿼리
```

---

### 2. 병목 지점별 상세 분석과 해결 방안

#### 병목 1: 클라이언트 단에서의 중복 요청

**문제 상황:**
- 수강신청 버튼을 연타하는 학생들
- 응답이 느리면 새로고침 → 중복 요청이 기하급수적으로 증가
- 실제 10,000명이 아니라 50,000건 이상의 요청이 발생

**해결 방안:**

```javascript
// 1. 프론트엔드: 버튼 비활성화 + 디바운싱
const enrollButton = document.getElementById('enroll');
enrollButton.addEventListener('click', async () => {
    enrollButton.disabled = true;
    enrollButton.textContent = '신청 중...';
    try {
        const response = await fetch('/api/enroll', {
            method: 'POST',
            headers: { 'X-Idempotency-Key': generateUUID() }, // 멱등성 키
            body: JSON.stringify({ courseId, studentId })
        });
    } finally {
        setTimeout(() => {
            enrollButton.disabled = false;
            enrollButton.textContent = '수강신청';
        }, 3000); // 3초 쿨다운
    }
});
```

```java
// 2. 서버: 멱등성 키로 중복 요청 필터링
@PostMapping("/api/enroll")
public ResponseEntity<?> enroll(
        @RequestHeader("X-Idempotency-Key") String idempotencyKey,
        @RequestBody EnrollRequest request) {

    // Redis에서 멱등성 키 확인 (TTL 30초)
    if (redisTemplate.hasKey("idempotency:" + idempotencyKey)) {
        return ResponseEntity.ok("이미 처리 중인 요청입니다.");
    }
    redisTemplate.opsForValue().set("idempotency:" + idempotencyKey, "processing", 30, TimeUnit.SECONDS);
    // ... 실제 처리
}
```

---

#### 병목 2: 로드밸런서 / 네트워크 계층

**문제 상황:**
- 단일 서버로는 10,000 TPS를 감당 불가
- SSL 핸드셰이크가 CPU를 과도하게 소비
- 하나의 서버가 죽으면 전체 장애로 이어짐

**해결 방안:**

```
                        ┌─── WAS 1 (Tomcat, 200 threads)
                        │
[Client] → [Nginx LB] ──┼─── WAS 2 (Tomcat, 200 threads)
           (L7, Round   │
            Robin)      ├─── WAS 3 (Tomcat, 200 threads)
                        │
                        └─── WAS 4 (Tomcat, 200 threads)
```

- **수평 확장(Scale-Out)**: WAS 서버를 4~5대 배치하여 요청 분산
- **Nginx**: L7 로드밸런서로 라운드 로빈 또는 Least Connection 방식 사용
- **SSL 종료(SSL Termination)**: Nginx에서 SSL을 처리하여 WAS의 부담 제거
- **Keep-Alive**: 커넥션 재사용으로 핸드셰이크 오버헤드 감소
- **Health Check**: 장애 서버 자동 제외

```nginx
upstream enrollment_servers {
    least_conn;
    server was1:8080 max_fails=3 fail_timeout=30s;
    server was2:8080 max_fails=3 fail_timeout=30s;
    server was3:8080 max_fails=3 fail_timeout=30s;
    server was4:8080 max_fails=3 fail_timeout=30s;
}

server {
    listen 443 ssl;
    ssl_certificate /etc/ssl/cert.pem;

    location /api/enroll {
        proxy_pass http://enrollment_servers;
        proxy_connect_timeout 5s;
        proxy_read_timeout 10s;

        # Rate Limiting: IP당 초당 10건 제한
        limit_req zone=enroll burst=20 nodelay;
    }
}
```

---

#### 병목 3: WAS 서버 - 스레드 풀 고갈

**문제 상황:**
- Tomcat 기본 스레드 200개 → 10,000 TPS 처리 불가능
- 모든 스레드가 DB 응답 대기 → 새 요청을 받을 수 없음
- 스레드가 모두 소진되면 요청이 큐에 쌓이고, 큐마저 넘치면 Connection Refused

**구체적 계산:**
```
DB 쿼리 응답 시간: 50ms (평균)
스레드 1개가 1초에 처리 가능한 요청: 1000ms / 50ms = 20건
200 스레드 × 20건 = 4,000 TPS (서버 1대)
10,000 TPS를 처리하려면 최소 3대 이상 필요
```

**해결 방안:**

```yaml
# application.yml - Tomcat 튜닝
server:
  tomcat:
    threads:
      max: 400          # 최대 스레드 수 증가
      min-spare: 100     # 유휴 스레드 유지
    max-connections: 10000
    accept-count: 500    # 대기 큐 크기
    connection-timeout: 5000  # 5초 타임아웃
```

추가로, 비동기 처리로 스레드 효율을 극대화할 수 있습니다:

```java
@PostMapping("/api/enroll")
public CompletableFuture<ResponseEntity<?>> enrollAsync(@RequestBody EnrollRequest request) {
    return CompletableFuture.supplyAsync(() -> {
        enrollmentService.enroll(request);
        return ResponseEntity.ok("수강신청 완료");
    }, enrollExecutor); // 전용 스레드풀 사용
}
```

---

#### 병목 4: 데이터베이스 - 가장 치명적인 병목

DB는 수강신청 시스템에서 **가장 심각한 병목 지점**입니다. 이유는:

**문제 상황 1 - 커넥션 풀 고갈:**
```
HikariCP 기본 커넥션: 10개
WAS 4대 × 10개 = 총 40개 커넥션
10,000 TPS에 40개 커넥션 → 심각한 대기 발생
```

**문제 상황 2 - 락 경합(Lock Contention):**
```sql
-- 인기 과목 (id=101)에 1,000명이 동시에 신청
BEGIN;
SELECT remaining_seats FROM course WHERE id = 101 FOR UPDATE;  -- 비관적 락
-- 999명이 이 락을 기다림 → 대기열 폭발
UPDATE course SET remaining_seats = remaining_seats - 1 WHERE id = 101;
COMMIT;
```

**문제 상황 3 - 슬로우 쿼리:**
- 수강 이력 조회, 시간표 중복 체크 등 복잡한 쿼리가 포함되면 응답 시간 급증
- 하나의 슬로우 쿼리가 커넥션을 점유 → 다른 요청 대기

---

### 3. 핵심 해결 전략: Redis 기반 대기열 + 재고 관리

DB 병목을 근본적으로 해결하기 위해 **Redis를 앞단에 배치**하여 요청을 제어합니다.

#### 전체 아키텍처

```
[클라이언트]
     │
     ▼
[Nginx LB + Rate Limit]
     │
     ▼
[WAS 서버 (4대)]
     │
     ├──▶ [Redis] ← 잔여석 관리 (DECR 원자 연산)
     │       │         대기열 관리 (Sorted Set)
     │       │         중복 신청 방지 (Set)
     │       │
     │       ▼
     │    성공 시에만
     │       │
     ▼       ▼
[Message Queue (Kafka)]
     │
     ▼
[DB Writer (Consumer)]
     │
     ▼
[MySQL - 최종 영속화]
```

#### 단계별 처리 흐름

**Step 1: Redis에서 잔여석 확인 및 차감 (원자적 연산)**

```java
@Service
public class EnrollmentService {

    private final StringRedisTemplate redisTemplate;

    public EnrollResult tryEnroll(Long courseId, Long studentId) {

        // 1. 중복 신청 체크 (Set 자료구조)
        String enrollKey = "enrolled:" + courseId;
        Boolean alreadyEnrolled = redisTemplate.opsForSet().isMember(enrollKey, studentId.toString());
        if (Boolean.TRUE.equals(alreadyEnrolled)) {
            return EnrollResult.ALREADY_ENROLLED;
        }

        // 2. 잔여석 차감 (DECR - 원자적 연산, 락 불필요)
        String stockKey = "course:stock:" + courseId;
        Long remaining = redisTemplate.opsForValue().decrement(stockKey);

        if (remaining == null || remaining < 0) {
            // 잔여석 없음 → 복구
            redisTemplate.opsForValue().increment(stockKey);
            return EnrollResult.NO_SEATS;
        }

        // 3. 신청 성공 → Set에 추가
        redisTemplate.opsForSet().add(enrollKey, studentId.toString());

        // 4. Kafka로 비동기 DB 저장 요청
        kafkaTemplate.send("enrollment-topic",
            new EnrollmentEvent(courseId, studentId, LocalDateTime.now()));

        return EnrollResult.SUCCESS;
    }
}
```

**왜 이 방식이 효과적인가:**
- Redis `DECR`은 **단일 스레드로 원자적**으로 실행 → 락 없이도 동시성 안전
- Redis는 초당 **100,000건 이상** 처리 가능 → 10,000 TPS를 충분히 감당
- DB에는 성공한 요청만 비동기로 저장 → DB 부하 대폭 감소

**Step 2: Kafka Consumer에서 DB 영속화**

```java
@KafkaListener(topics = "enrollment-topic", groupId = "enrollment-consumer")
public void processEnrollment(EnrollmentEvent event) {
    // DB에 최종 저장 (배치 처리 가능)
    Enrollment enrollment = Enrollment.builder()
        .courseId(event.getCourseId())
        .studentId(event.getStudentId())
        .enrolledAt(event.getTimestamp())
        .build();
    enrollmentRepository.save(enrollment);

    // 과목 테이블 잔여석 업데이트
    courseRepository.decrementSeats(event.getCourseId());
}
```

---

### 4. 대기열 시스템 (추가 보호 장치)

인기 과목에 몰리는 요청을 더 세밀하게 제어하기 위해 **대기열 시스템**을 도입합니다.

```java
@Service
public class WaitingQueueService {

    // Sorted Set: score = 타임스탬프, member = studentId
    public long enterQueue(Long courseId, Long studentId) {
        String queueKey = "queue:" + courseId;
        double score = System.currentTimeMillis();
        redisTemplate.opsForZSet().add(queueKey, studentId.toString(), score);

        // 현재 대기 순번 반환
        Long rank = redisTemplate.opsForZSet().rank(queueKey, studentId.toString());
        return rank != null ? rank + 1 : -1;
    }

    // 스케줄러: 주기적으로 대기열에서 꺼내서 처리
    @Scheduled(fixedDelay = 1000) // 1초마다
    public void processQueue() {
        for (Long courseId : activeCourses) {
            String queueKey = "queue:" + courseId;
            // 상위 100명씩 꺼내서 처리
            Set<String> students = redisTemplate.opsForZSet().range(queueKey, 0, 99);
            if (students != null) {
                for (String studentId : students) {
                    enrollmentService.tryEnroll(courseId, Long.parseLong(studentId));
                    redisTemplate.opsForZSet().remove(queueKey, studentId);
                }
            }
        }
    }
}
```

---

### 5. DB 최적화 (최후의 방어선)

Redis와 메시지 큐로 대부분의 부하를 흡수하더라도, DB 자체의 최적화도 필요합니다.

**커넥션 풀 튜닝:**
```yaml
spring:
  datasource:
    hikari:
      maximum-pool-size: 50        # 서버당 50개
      minimum-idle: 20
      connection-timeout: 3000     # 3초 내 커넥션 못 얻으면 실패
      max-lifetime: 1800000        # 30분
      leak-detection-threshold: 5000
```

**인덱스 최적화:**
```sql
-- 수강신청 테이블: 중복 체크를 위한 유니크 인덱스
CREATE UNIQUE INDEX idx_enrollment_course_student
ON enrollment (course_id, student_id);

-- 과목 테이블: 잔여석 조회 최적화
CREATE INDEX idx_course_remaining ON course (id, remaining_seats);
```

**Read/Write 분리:**
```
[WAS] ──쓰기──▶ [MySQL Primary]
       │                 │
       │              복제(Replication)
       │                 │
       └──읽기──▶ [MySQL Replica 1]
                 [MySQL Replica 2]
```

- 수강 이력 조회, 시간표 조회 등 **읽기 쿼리**는 Replica에서 처리
- 수강신청 **쓰기 쿼리**만 Primary로 전달
- 쓰기 트래픽이 줄어 Primary의 부하 대폭 감소

---

### 6. 캐시 레이어를 통한 성능 향상

수강신청 시스템에서는 신청 요청 자체뿐 아니라, **과목 목록 조회**, **잔여석 확인**, **시간표 중복 검증** 등 읽기 요청도 대량으로 발생합니다. 이를 매번 DB에서 조회하면 DB에 불필요한 부하가 가중됩니다. **다중 캐시 레이어(Multi-Level Cache)** 를 도입하면 DB 접근을 극적으로 줄일 수 있습니다.

#### 캐시 대상 분석

| 데이터 | 변경 빈도 | 캐시 전략 | TTL |
|--------|----------|----------|-----|
| 과목 목록 (이름, 교수, 학점) | 거의 없음 | Local Cache + Redis | 1시간 |
| 잔여석 수 | 매우 높음 | Redis (DECR로 이미 관리) | 실시간 |
| 학생의 시간표 | 신청 시에만 변경 | Redis Hash | 5분 |
| 수강 선수과목 조건 | 학기 중 변경 없음 | Local Cache | 24시간 |
| 수강신청 가능 과목 필터 결과 | 학생마다 다름 | Redis (학생별 키) | 3분 |

#### Multi-Level Cache 구조

```
[WAS 요청 처리]
     │
     ▼
[L1: Local Cache (Caffeine)]  ← 서버 메모리, 지연 시간 ~0.1ms
     │  MISS
     ▼
[L2: Redis Cache]             ← 네트워크 호출, 지연 시간 ~1ms
     │  MISS
     ▼
[L3: MySQL DB]                ← 디스크 I/O, 지연 시간 ~5-50ms
```

**왜 2단계 캐시가 필요한가:**
- L1(Local Cache)만 사용하면 WAS 4대가 각각 다른 데이터를 캐싱 → 정합성 문제
- L2(Redis)만 사용하면 모든 요청이 네트워크를 타야 함 → 불필요한 지연
- L1 + L2 조합으로 **속도와 정합성을 동시에 확보**

#### 구현 예시

**Caffeine (L1) + Redis (L2) 설정:**

```java
@Configuration
@EnableCaching
public class CacheConfig {

    @Bean
    public CacheManager cacheManager(RedisConnectionFactory redisConnectionFactory) {
        // L1: Caffeine Local Cache
        CaffeineCacheManager localCacheManager = new CaffeineCacheManager();
        localCacheManager.setCaffeine(Caffeine.newBuilder()
            .maximumSize(10_000)         // 최대 10,000개 항목
            .expireAfterWrite(5, TimeUnit.MINUTES)  // 5분 후 만료
            .recordStats());             // 캐시 적중률 모니터링

        // L2: Redis Cache
        RedisCacheConfiguration redisConfig = RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofMinutes(30))
            .serializeValuesWith(
                RedisSerializationContext.SerializationPair
                    .fromSerializer(new GenericJackson2JsonRedisSerializer()));

        RedisCacheManager redisCacheManager = RedisCacheManager.builder(redisConnectionFactory)
            .cacheDefaults(redisConfig)
            .withCacheConfiguration("courseList",
                redisConfig.entryTtl(Duration.ofHours(1)))   // 과목 목록: 1시간
            .withCacheConfiguration("prerequisite",
                redisConfig.entryTtl(Duration.ofHours(24)))  // 선수과목: 24시간
            .withCacheConfiguration("studentSchedule",
                redisConfig.entryTtl(Duration.ofMinutes(5))) // 시간표: 5분
            .build();

        // L1 → L2 순서로 조회하는 CompositeCacheManager
        CompositeCacheManager compositeCacheManager = new CompositeCacheManager();
        compositeCacheManager.setCacheManagers(List.of(localCacheManager, redisCacheManager));
        return compositeCacheManager;
    }
}
```

**과목 목록 조회 - Cache-Aside 패턴:**

```java
@Service
public class CourseQueryService {

    @Cacheable(value = "courseList", key = "'semester:' + #semester")
    public List<CourseDto> getCourseList(String semester) {
        // 캐시 MISS 시에만 DB 조회
        return courseRepository.findBySemester(semester)
            .stream()
            .map(CourseDto::from)
            .toList();
    }

    // 수강신청 성공 후 관련 캐시 무효화
    @CacheEvict(value = "courseList", key = "'semester:' + #semester")
    public void evictCourseListCache(String semester) {
        // 캐시만 삭제, DB 조작 없음
    }
}
```

**시간표 중복 체크 - Redis Hash 활용:**

```java
@Service
public class ScheduleCacheService {

    // 학생의 시간표를 Redis Hash로 캐싱
    // Key: "schedule:{studentId}", Field: "MON_09:00", Value: "courseId:101"
    public boolean hasTimeConflict(Long studentId, Long courseId) {
        String scheduleKey = "schedule:" + studentId;

        // 1. Redis에서 시간표 조회 (L2)
        Map<Object, Object> cachedSchedule = redisTemplate.opsForHash().entries(scheduleKey);

        if (cachedSchedule.isEmpty()) {
            // 캐시 MISS → DB에서 로드 후 Redis에 저장
            List<ScheduleSlot> slots = scheduleRepository.findByStudentId(studentId);
            for (ScheduleSlot slot : slots) {
                redisTemplate.opsForHash().put(scheduleKey,
                    slot.getDayTime(), slot.getCourseId().toString());
            }
            redisTemplate.expire(scheduleKey, 5, TimeUnit.MINUTES);
            cachedSchedule = redisTemplate.opsForHash().entries(scheduleKey);
        }

        // 2. 신청하려는 과목의 시간대와 충돌 확인
        List<String> newCourseSlots = courseTimeSlotRepository.findSlotsByCourseId(courseId);
        for (String slot : newCourseSlots) {
            if (cachedSchedule.containsKey(slot)) {
                return true; // 시간표 충돌
            }
        }
        return false;
    }

    // 수강신청 성공 시 시간표 캐시 업데이트
    public void updateScheduleCache(Long studentId, Long courseId, List<String> timeSlots) {
        String scheduleKey = "schedule:" + studentId;
        for (String slot : timeSlots) {
            redisTemplate.opsForHash().put(scheduleKey, slot, courseId.toString());
        }
    }
}
```

#### 캐시 도입 전후 성능 비교

```
[캐시 없음]
과목 목록 조회: 10,000 req/s × DB 쿼리 5ms = DB에 초당 10,000건 조회
시간표 체크:    8,000 req/s × DB 쿼리 10ms = DB에 초당 8,000건 조회
→ DB 읽기 부하: 초당 18,000건

[캐시 도입 후] (캐시 적중률 95% 가정)
과목 목록 조회: 10,000 × 5% = DB에 초당 500건 (L1에서 95% 응답)
시간표 체크:    8,000 × 5% = DB에 초당 400건 (L2 Redis에서 95% 응답)
→ DB 읽기 부하: 초당 900건 (95% 감소)
```

#### 캐시 사용 시 주의사항

**1. 캐시 스탬피드 (Cache Stampede) 방지:**
```java
// 인기 과목의 캐시가 동시에 만료되면 수천 건이 동시에 DB 조회
// → 분산 락으로 한 번만 DB 조회하고 나머지는 캐시 대기
public CourseDto getCourseWithLock(Long courseId) {
    String cacheKey = "course:" + courseId;
    String lockKey = "lock:course:" + courseId;

    CourseDto cached = getCacheValue(cacheKey);
    if (cached != null) return cached;

    // 분산 락 획득 시도 (SETNX)
    Boolean acquired = redisTemplate.opsForValue()
        .setIfAbsent(lockKey, "locked", 5, TimeUnit.SECONDS);

    if (Boolean.TRUE.equals(acquired)) {
        try {
            // DB 조회 후 캐시 저장
            CourseDto course = courseRepository.findById(courseId).map(CourseDto::from).orElse(null);
            setCacheValue(cacheKey, course, 1, TimeUnit.HOURS);
            return course;
        } finally {
            redisTemplate.delete(lockKey);
        }
    } else {
        // 다른 스레드가 이미 DB 조회 중 → 짧은 대기 후 캐시 재확인
        Thread.sleep(50);
        return getCacheValue(cacheKey);
    }
}
```

**2. 캐시 무효화 전략:**
- 수강신청 성공 시 → 해당 학생의 시간표 캐시 갱신, 과목 잔여석은 Redis에서 이미 실시간 관리
- 관리자가 과목 정보 변경 시 → `@CacheEvict`로 해당 과목 캐시 삭제
- TTL 기반 자동 만료를 기본으로, 중요 이벤트 발생 시 명시적 무효화 병행

---

### 7. 전체 아키텍처 요약

```
                    ┌─────────────────────────────────────────────┐
                    │              System Architecture             │
                    └─────────────────────────────────────────────┘

[학생 브라우저]
   │  ① 버튼 비활성화 + 멱등성 키
   ▼
[CDN] ── 정적 리소스 캐싱 (HTML, JS, CSS)
   │
   ▼
[Nginx L7 LB]
   │  ② Rate Limiting (IP당 10req/s)
   │  ③ SSL Termination
   │  ④ Least Connection 분산
   ▼
[WAS 1] [WAS 2] [WAS 3] [WAS 4]
   │  ⑤ L1 Local Cache (Caffeine) - 과목 목록, 선수과목
   │  ⑥ 멱등성 키 검증 (Redis)
   │  ⑦ L2 Redis Cache - 시간표, 과목 필터
   │  ⑧ 잔여석 차감 (Redis DECR)
   │  ⑨ 중복 신청 체크 (Redis Set)
   ▼
[Redis Cluster]  ← 핵심: 100,000+ TPS (캐시 + 재고 + 대기열)
   │
   │  성공한 요청만
   ▼
[Kafka / Message Queue]
   │  ⑩ 비동기 처리
   ▼
[DB Writer Consumer]
   │  ⑪ 배치 저장
   ▼
[MySQL Primary] ──복제──▶ [MySQL Replica × 2]
```

**각 계층이 흡수하는 트래픽:**

| 계층 | 들어오는 요청 | 처리 후 남는 요청 | 감소율 |
|------|-------------|-----------------|--------|
| 프론트엔드 (디바운싱) | 50,000 | 15,000 | 70% 감소 |
| Nginx Rate Limit | 15,000 | 10,000 | 33% 감소 |
| 멱등성 키 필터링 | 10,000 | 8,000 | 20% 감소 |
| Redis 잔여석 체크 | 8,000 | 500 (성공) | 94% 감소 |
| **DB 최종 쓰기** | **500** | **500** | **DB는 여유** |

핵심은 **DB에 도달하는 요청을 최소화**하는 것입니다.

---

### 8. 장애 대응 시나리오

**Redis 장애 시:**
- Redis Sentinel 또는 Redis Cluster로 자동 페일오버
- Redis가 완전히 죽으면 → DB 비관적 락으로 폴백 (성능 저하 허용)

**Kafka 장애 시:**
- Kafka 브로커 3대 이상 구성 (Replication Factor 3)
- Consumer 지연 시 → 수강신청 결과를 "처리 중"으로 응답, 이후 알림

**WAS 장애 시:**
- Nginx Health Check로 장애 서버 자동 제외
- Auto Scaling 정책으로 트래픽 기반 자동 증설

## 핵심 정리
- 수강신청 시스템의 **최대 병목은 DB**이며, Redis를 앞단에 배치하여 DB 접근을 최소화하는 것이 핵심
- Redis `DECR`의 원자적 연산으로 락 없이 잔여석 관리 가능 (100,000+ TPS)
- 성공한 요청만 Kafka를 통해 비동기로 DB에 저장하면 DB 부하가 극적으로 감소
- 프론트엔드 디바운싱 → Nginx Rate Limit → 멱등성 키 → Redis 순으로 계층별 트래픽 필터링
- 대기열 시스템으로 순간 폭주를 평탄화(Traffic Smoothing)하여 안정적 처리
- Read/Write 분리와 커넥션 풀 튜닝으로 DB 자체의 처리량도 극대화
- Multi-Level Cache(L1 Local + L2 Redis)로 읽기 부하를 95% 이상 감소시킬 수 있음
- 캐시 스탬피드 방지를 위해 분산 락 활용 필요

## 키워드

### 순간 폭주 (Flash Crowd)
특정 시간대에 극단적으로 트래픽이 집중되는 현상입니다. 수강신청, 콘서트 티켓팅, 선착순 이벤트 등에서 발생하며, 일반적인 상황 대비 100배 이상의 트래픽이 몰릴 수 있습니다. 이에 대응하기 위해 대기열, 캐싱, 비동기 처리 등의 전략이 필요합니다.

### Rate Limiting
특정 시간 내에 허용되는 요청 수를 제한하는 기법입니다. Token Bucket, Sliding Window 등의 알고리즘이 있으며, Nginx의 `limit_req` 모듈이나 API Gateway에서 구현합니다. 악의적인 대량 요청이나 봇의 접근을 차단하는 데도 사용됩니다.

### 멱등성 (Idempotency)
같은 요청을 여러 번 보내도 결과가 동일하게 유지되는 성질입니다. 클라이언트가 고유한 멱등성 키를 함께 전송하면, 서버는 이를 Redis에 캐싱하여 중복 요청을 필터링합니다. 네트워크 장애로 인한 재전송에도 안전하게 동작합니다.

### Redis 원자적 연산 (Atomic Operation)
Redis는 싱글 스레드로 명령어를 순차 처리하기 때문에 `INCR`, `DECR`, `SETNX` 등의 명령이 별도의 락 없이도 원자적으로 실행됩니다. 이를 활용하면 분산 환경에서도 안전하게 카운터를 관리할 수 있습니다.

### 메시지 큐 (Message Queue)
프로듀서와 컨슈머 사이에서 메시지를 비동기로 전달하는 시스템입니다. Kafka, RabbitMQ 등이 대표적이며, 수강신청에서는 Redis에서 성공한 요청을 Kafka로 전달하여 DB 쓰기를 비동기로 처리합니다. 이를 통해 WAS와 DB 간의 결합도를 낮춥니다.

### 커넥션 풀 (Connection Pool)
미리 데이터베이스 커넥션을 만들어 놓고 재사용하는 기법입니다. HikariCP가 대표적이며, `maximum-pool-size`, `connection-timeout` 등의 설정을 통해 커넥션 고갈을 방지합니다. 풀 크기가 너무 작으면 대기가 발생하고, 너무 크면 DB에 과부하가 걸립니다.

### 스케일 아웃 (Scale-Out)
서버의 수를 늘려 처리 능력을 확장하는 방식입니다. 스케일 업(서버 사양 업그레이드)과 대비되며, WAS 서버를 여러 대 두고 로드밸런서로 분산하는 것이 대표적입니다. 무상태(Stateless) 설계가 전제되어야 효과적으로 적용할 수 있습니다.

### 데드락 (Deadlock)
두 개 이상의 트랜잭션이 서로가 가진 락을 기다리며 무한 대기하는 상태입니다. 수강신청에서 여러 과목을 동시에 락 걸 때 발생할 수 있으며, Redis 기반 아키텍처로 DB 락 사용을 최소화하면 데드락 위험도 크게 줄일 수 있습니다.

### SSL 종료 (SSL Termination)
로드밸런서(Nginx)에서 HTTPS 암호화/복호화를 처리하고, 내부 WAS와는 HTTP로 통신하는 방식입니다. WAS의 CPU 부담을 줄이고, 인증서 관리를 한 곳에서 집중할 수 있습니다.

### 트래픽 평탄화 (Traffic Smoothing)
순간적으로 몰리는 요청을 대기열 등을 활용하여 일정한 속도로 처리하는 기법입니다. 수강신청에서는 Redis Sorted Set 기반 대기열을 사용하여 초당 처리량을 제어하고, 서버와 DB의 과부하를 방지합니다.

### Multi-Level Cache (다중 캐시 레이어)
L1(Local Cache)과 L2(Redis Cache)를 계층적으로 구성하여 캐시 적중률과 응답 속도를 극대화하는 전략입니다. L1은 서버 메모리에서 ~0.1ms로 응답하고, L1 미스 시 L2 Redis에서 ~1ms로 응답합니다. DB 조회(~5-50ms)는 두 캐시 모두 미스일 때만 발생하여 읽기 부하를 95% 이상 줄일 수 있습니다.

### 캐시 스탬피드 (Cache Stampede)
인기 데이터의 캐시가 만료되는 순간 수천 건의 요청이 동시에 DB로 몰리는 현상입니다. Thundering Herd 문제라고도 합니다. 분산 락(SETNX)을 사용하여 한 요청만 DB를 조회하고 나머지는 캐시가 갱신될 때까지 대기하게 하여 방지합니다.

### Cache-Aside 패턴
애플리케이션이 먼저 캐시를 조회하고, 캐시 미스 시 DB에서 조회한 뒤 결과를 캐시에 저장하는 패턴입니다. Spring의 `@Cacheable` 어노테이션으로 쉽게 구현할 수 있으며, 캐시 무효화는 `@CacheEvict`로 처리합니다. 읽기가 많고 쓰기가 적은 데이터에 적합합니다.

## 참고 자료
- [Redis 공식 문서 - DECR](https://redis.io/commands/decr/)
- [Redis 공식 문서 - Sorted Sets](https://redis.io/docs/data-types/sorted-sets/)
- [Apache Kafka 공식 문서](https://kafka.apache.org/documentation/)
- [Nginx 공식 문서 - Rate Limiting](https://www.nginx.com/blog/rate-limiting-nginx/)
- [HikariCP 공식 문서](https://github.com/brettwooldridge/HikariCP)
- [MySQL 공식 문서 - InnoDB Locking](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html)
- [Spring Boot 공식 문서 - Common Application Properties](https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html)
